Mostly from [[http:cs50.harvard.edu][Harvard's CS50]] course.

** Data Structures
*** Hash table

- Collision resolution:
  1) Linear probing
     linear probing searches the table for the closest following
     free location and inserts the new key there.

  2) Separate chaining
     It uses linked lists

- A good hash function:
  1. Makes use of all info provided by key
  2. Hash values should spread evenly across hash tables (in order to
     reduce the length of linked lists)

*** Singly Linked List
Arrays are very inflexible when it comes to resizing.

- Singly Linked Lists are easy to grow and shrink without any wasted space.
- We don't have random access.
- A linked list *node* is a special kind of [[structs]] with two members:
  1. Data of some data type (int, char, float)
  2. A pointer to another node of the same type
  #+BEGIN_SRC C
    typedef struct sllist           /* sllist is a temperary name because the type we're defining is self-referential */
    {
      SOME_TYPE val;
      struct sllist* next;          /* it's a pointer to another linked list */
    }
      sllnode;                      /* the permanent name of our new defined type */
  #+END_SRC

- A few operations that we need to understand:
  1. How to create a linked list when it doesn't already exist?
     #+BEGIN_SRC c
     sllnode* create(SOME_TYPE val);
     #+END_SRC
     Steps involved:
     1. Dynaically allocate space for a new =sllnode=.
     2. Check to make sure we didn't run out of memory.
     3. Initialize the node's =val= field.
     4. Initialize the node's =next= field. It's =NULL= if it's the only node.
     5. Return a pointer to the newly created =sllnode=.
  2. Search through a linked list to find an element.
     #+BEGIN_SRC c
     bool find(sllnode* head, SOME_TYPE val)
     #+END_SRC
     Steps involved:
       1. Created a traversal pointer pointing to the list's head.
       2. If the current node's =val= is what we're looking for, report success.
       3. If not, set the traversal pointer to the next pointer in the list and go back to steb (2).
       4. If you reached the end of the list, report failure.
  3. Insert a new node into the linked list.
     #+BEGIN_SRC C
     sllnode* insert(sllnode* head, SOME_TYPE val)
     #+END_SRC
     Steps involved:
       1. Dynamically allocate space for a new sllnode.
       2. Check to make sure we didn't run out of memory.
       3. Insert the ndoe *at the beginning of the linked list*.
       4. Return a pointer to the new head of the linked list.
  4. Delete a single element from a linked list.
     With singly-linked list it's kinda clunky, check [[Doubly-Linked Lists]].
  5. Delete an entire linked list.
     #+BEGIN_SRC C
     void destroy(sllnode* head)
     #+END_SRC
     Steps involved:
       1. If you've reached a null pointer, stop.
       2. Delete *the rest of the list*. If we start the deletion from
          top->bottom (and not bottom->top), well, we can't. We free
          the head and there's no way to access the rest of the
          list. And memory leak happens. (‚ïØ¬∞‚ñ°¬∞)‚ïØÔ∏µ ‚îª‚îÅ‚îª
       3. Free the current node.

*** Doubly-Linked Lists
- In singly-linkeds we can only ever move in one direction through the
  list.
- A doubly-linked list allows us to move forward and backward through
  the list, all by simly adding one extra pointer to our =struct=
  definition.
#+BEGIN_SRC C
  typedef struct dllist
  {
    SOME_TYPE val;
    struct dllist* prev;
    struct dllist* next;
  }
    dllnode;
#+END_SRC

*** Array
- We use arrays to hold values of the *same type* at contiguous memory
  locations.
- Which has been partiioned into small, identically-sized block of
  spaced called elements.
- Can be accessed directly by an index number (so-called *random
  access*) so they are great for element lookup.
- In some programming languages (like in C) going behind alocated
  memory, may cause a [[https://en.wikipedia.org/wiki/Segmentation_fault][Segmentation fault]].
- In memory, two dimensional arrays are no different than
  one-dimensional. They're just for human perception.
- Arrays are usually *passed by reference* to the callee, not a copy
  of it. If that's the case we can say an array's name is actually a
  pointer to its first element. See [[Pointer (in C)]]

*** struct
    or structures
- Structures provide a way to unify serveral variables of different
  types into a single, new variable type which can be assigned its own
  type name.
- We use structures(structs) to group together elements of a variety
  of data types that have a logical connection.
#+BEGIN_SRC C
   struct car
   {
     int year;
     char model[10];
     char plate[7];
     int odometer;
     double engine_size;
   };
   struct car maycar;
   maycar.year = 23;
#+END_SRC

*** Trie
   /traƒ±/
- Tries combine structures and pointers together to store data in an
  intersting way.
- The data to be searched for in the trie is now a roadmap.
  - If you can follow the map from beginning to end, the data exist in the trie.
  - If you can't it doesn't exist.
- Unlike with a hash table, there are no collisions, and no two pieces
  of data (unless they are identical) have the same path.
- To insert an element into the trie, simply build the correct path from the root to the leaf.
- To search for an element in the trie, use successive digits to
  navigate from the root, and if you can make it to the end without
  hitting a dead end (a NULL pointer), you've fount it.

#+BEGIN_SRC C
  typedef struct _trie
  {
    char university[20];
    struct _trie* paths[10];
  }
    trie;
#+END_SRC
*** Stack
- This data structure is commonly implemented in one of two ways: as
  an *array* or as a *linked* list.
- In either case, the important rule is that when data is added to the
  stack, it sits "on top," and so if an element needs to be removed,
  the most recently added element is the only element that can legally
  be removed.
- /Last in, first out/ (LIFO)
- So there only two operations that may legally be performed on a
  stack.
  - *push*: Add a new element to the top of the stack.
  - *pop*: Remove the most recently-added element from the top of the
    stack.
- Array-based implementation
  #+BEGIN_SRC C
    typedef struct _stack
    {
      SOME_VALUE array[CAPACITY];
      int top;
    }
      stack;
  #+END_SRC
  In general case push() needs to:
  + Accept a pointer to the stack.
  + Accept data of SOME_VALUE to be added to the stack.
  + Add that data to the stack at the top of the stack.
  + Change the location of the top of the stack.
  
  In Gerneral case, pop() needs to:
  + Accept a pointer to the stack.
  + Change the location of the top of the stack.
  + Return the value that was removed ('remove' is used loosely, we just
    ignore the value and pretend that it doesn't exist anymore) from the
    stack.
*** Queue
- This data structure is commonly implemented in one of two ways: 1)
  as an array or as a linked list.
- In either case, the important rule is that when data is added to the
  queue, it is tacked onto the end, and so if an element needs to be
  removed, the element at the front is the only element that can
  legally be removed.
- /First in, first out/ (FIFO)
- There are only two operations that may legally be performed:
  + *Enqueue*: Add a new element to the /end/ of the queue.
  + *Dequeue*: Remove the oldest element from the /front/ of the queue.

#+BEGIN_SRC C
  typedef struct _queue
  {
    SOME_VALUE array[CAPACITY];
    int front;
    int size;
  }
    queue;
#+END_SRC

** Algorithms
*** Computational Complexity
- Being able to analyze an algorithm allows us to have an idea of how
  well it scales as we throw larger and larger data sets at it.
- When we talk about the complexity of an algorithm, we generally
  refer to the worst-case senario. We refer to this as O.
- We sometimes also care about the best-case senario. We refer to this as ùõÄ.
- What is a data set? Whatever makes the most sense in context.
- We can measure an algorithm based on how it handles these input. Let's call this measure f(n).
- We don't actually care about what f(n) is precisely. Rather, we care
  only about its tendency, which is dictated by its highest-order
  term.

| n         | fn(n) = n^3   | f(n) = n^3 + n^2 | f(n) = n^3 - 8n^2 + 20n |
|-----------+---------------+------------------+-------------------------|
| 1         | 1             | 2                | 13                      |
| 10        | 1,000         | 1,100            | 400                     |
| 1,000     | 1,000,000,000 | 1,001,000,000    | 992,020,000             |
| 1,000,000 | 1.0 √ó 10^18   | 1.000001 √ó 10^18 | 9.99992 √ó 10^17         |
|           |               |                  |                         |

Some more common Computational Complexity

| O(1)       | Constant time     |
| O(log n)   | logarithmic time  |
| O(n)       | linear time       |
| O(n log n) | linearithmic time |
| O(n^2)     | quadratic time    |
| O(n^c)     | polynomial time   |
| O(C^n)     | exponential time  |
| O(n!)      | factorial time    |
| O(‚àû)       | infinite time     |

|------------------+-----------------+--------------------+----------------+-----------|
| Algorithm        | Time Complexity | 	Space Complexity |                |           |
|------------------+-----------------+--------------------+----------------+-----------|
|                  | Best            | Average            | Worst          | 	Worst   |
|------------------+-----------------+--------------------+----------------+-----------|
| Quicksort    	  | Œ©(n log(n))     | ‚≤ê(n log(n))        | O(n^2)         | O(log(n)) |
| Mergesort    	  | Œ©(n log(n))     | ‚≤ê(n log(n))        | O(n log(n))    | O(n)      |
| Timsort      	  | Œ©(n)            | ‚≤ê(n log(n))        | O(n log(n))    | O(n)      |
| Heapsort     	  | Œ©(n log(n))     | ‚≤ê(n log(n))        | O(n log(n))    | O(1)      |
| Bubble Sort  	  | Œ©(n)            | ‚≤ê(n^2)             | O(n^2)         | O(1)      |
| Insertion Sort	 | Œ©(n)            | ‚≤ê(n^2)             | O(n^2)         | O(1)      |
| Selection Sort	 | Œ©(n^2)          | ‚≤ê(n^2)             | O(n^2)         | O(1)      |
| Tree Sort    	  | Œ©(n log(n))     | ‚≤ê(n log(n))        | O(n^2)         | O(n)      |
| Shell Sort       | Œ©(n log(n))     | ‚≤ê(n(log(n))^2)     | O(n(log(n))^2) | O(1)      |
| Bucket Sort      | Œ©(n+k)          | ‚≤ê(n+k)             | O(n^2)         | O(n)      |
| Radix Sort       | Œ©(nk)           | ‚≤ê(nk)              | O(nk)          | O(n+k)    |
| Counting Sort	  | Œ©(n+k)          | ‚≤ê(n+k)             | O(n+k)         | O(k)      |
| Cubesort     	  | Œ©(n)            | ‚≤ê(n log(n))        | O(n log(n))    | O(n)      |

*** Sort
**** Bubble sort
- In pseudocode:
  * Set a flag to false
  * Repeate while flag is false
    + Set flag to true
    + Look at each adjacent pair
      - If two adjacent elements are not in order , swap them and set the flag to false.

- Worst-case scenario O(n^2) because we have to make n iteration
  through the list and checking all n elements each pass through.
- Best-case scenario ùõÄ(n) (we have to make n comparison even for sorted arrays)
- After k iteration, last k elements are in their proper place so we can
  ignore them.

PHP implementation:
#+BEGIN_SRC php
  <?php

  function bubble_sort($arr) {
      $is_sorted = false;

      while (! $is_sorted) {
          $is_sorted = true;

          $arr_length_minus_one = count($arr) - 1; // because we don't wanna go out of bound
          $last_unsorted_item = $arr_length_minus_one;

          for($i = 0; $i < $last_unsorted_item; $i++) {
              if ($arr[$i] > $arr[$i + 1]) {
                  $is_sorted = false;

                  $temp = $arr[$i];
                  $arr[$i] = $arr[$i + 1];
                  $arr[$i + 1] = $temp;
              }
          }
          $last_unsorted_item -= 1;
      }

      return $arr;
  }

  print_r(bubble_sort([2, 1, 3, 5, 4, 6]));
#+END_SRC
**** Insertion sort
The idea is to build the sorted array in place, shifting elements out
of the way if necessary to make room as we go.

- In pseudocode:
  + Call the first elment of the array /sorted/
  + Repeat until all elements are sorted:
    * Look at the next unsorted element. Insert into the "sorted"
      portion by shifting the requisite number of elements.
- Worst-case scenario: The array is in reverse order; we have to shift
  each of the n elements n positions each time we make an insertion => O(n^2)

- Best-case scenario: The array is already sorted => ùõÄ(n)

PHP implementation:
#+BEGIN_SRC php
<?php

function insertion_sort ($arr) {
    $arr_len = count($arr);
    $second_element_in_the_arr = 1;

    for($i = $second_element_in_the_arr; $i < $arr_len; $i++) {
        $element = $arr[$i];
        $j = $i;

        // iterate over the sorted portion from right to left
        // stop iteration when the element to the left of our current position is less than the current element we are trying to insert
        // we are moving through the sorted portion from right to left but moving through unsorted portion from left to right
        while ($j > 0 and $arr[$j - 1] > $element) {
            $arr[$j] = $arr[$j - 1]; // shif elements one space to the right
            $j -= 1;                 // in sorted section go one element to the left
        }

        $arr[$j] = $element;
    }

    return $arr;
}
#+END_SRC

**** Merge Sort
- In merge sort, the idea of the algorithm is to sort smaller arrays
  and then combine those arrays together (merge them) in sorted order.
- In pseudocode
  1. Sort the left half of the array (assuming n > 1) // if an array is consist of a single element it's already sorted.
  2. Sort the right half of the array (assuming n > 1)
  3. Merge the two halves together
- *Worst-case scenario*: We have to split /n/ elements up and recombine
  them, effectively doubling the sorted subarrays as we build them
  up. (combining sorted 1-element arrays into 2-element arrys,
  combined sorted 2-element arrays into 4-element arrays...) => O(n log n)
- *Worst-case scenario*: The array is already perfectly sorted. But we
  stil have tosplit and recombine it back together. => ùõÄ(n log n)
- Its space complexity is O(n)
PHP implementation:
#+BEGIN_SRC php

#+END_SRC
*** Search
**** Linear search
     Worst-case scenario O(n)
     Best-case scenario ùõÄ(1)

**** Binary search
- In binary search, the idea of the algorithm is to divide and
  conquer, reducing the search area by half each time, trying to find
  a target number.
- Array must be sorted.
- In pseudocode (we need to keep track of =target_element=, =start_index=, =end_index=, =middle_index=):
  + Repeat until the (sub)array is of size 0:
    * Calculate the middle point of the current (sub)array.
    * if the target is at the middle, stop.
    * Otherwise, if the target is less than what's at the middle,
      repeat, changing the end point to be just the left of the
      middle.
    * Otherwise, if the target is greater than what's at the middle,
      repeat, changeing the start point to be just to the right of the
      middle.
    * Remember: =start_index= < =end_index= should always evaluate to =true= or
      else =target_element= doesn't exist in the given array.
- In the worst case, binary search requires O(log n) time on a sorted
  array with n elements. In general, we can split search region in
  half [log_2 n] + 1 times before it becomes empty.
- Best-case scenario: ùõÄ(1)

=> if k = log_2 n then 2^k = n
=> so k times we can multiply 1 by 2 until we get to n
=> that is to say, we can divide n by 2 for k times until we get to 1

PHP implementation (‚ïØ¬∞‚ñ°¬∞)‚ïØÔ∏µ ‚îª‚îÅ‚îª
#+BEGIN_SRC php
  <?php
  function binary_search($arr, $target) {

      return do_binary_search($arr, $target, 0, count($arr) - 1);
  }

  function do_binary_search($arr, $target, $start_index, $end_index) {
      if($start_index > $end_index) {

          return false;
      }

      $mid = floor(($start_index + $end_index) / 2);

      if($arr[$mid] == $target) {

          return $mid;
      } elseif ($target < $arr[$mid]) {

          return do_binary_search($arr, $target, $start_index, $mid - 1);
      } else {

          return do_binary_search($arr, $target, $mid + 1, $end_index);
      }
  }

  echo binary_search([1, 2, 8, 9], 9); // 3
#+END_SRC

- see [[https://www.cs.cmu.edu/~15110-f12/Unit05PtB-handout.pdf][cs.cmu.edu]]

*** Breadth First
*** Depth First
** Networks
*** Internet
These are rudimentarified stuff for pea-brain people like me.

- As originally developed, the IP addressing scheme would effectively
  allocate a unique 32-bit address to each device hoping to connect
  to the internet.

- Instead of representing these 32-bit addresses as hexadecimal(as we
  do with memory locations), we represent them as four clusters of
  8-bits (4 * 8 bits = 32 bits) using decimal notation.

- For e.g. =w.x.y.z= where each letter is a non-negative value in the range of [0, 255] like 123.45.67.89

- If each IP address is 32 bits, that means there are roughly 4
  billion addresses to give out. That is no enough. The remedy is
  IPv6 (verses IPv4) that assigns 128-bit addresses instead of 32-bit
  addresses.

- In IPv6 we have 8 clusters of 16 bits (8 * 16 bits = 128 bits). For
  e.g =s:t:u:v:w:x:y:z= where each letter is represented by 1 to 4
  hexadecimal digits in the range of [0, ffff] like
  =1234:5678:90ab:cdef:fedc:ba09:8765:4321=

**** DHCP
How do we get an IP address? How do we know if one is free or taken?
There's a Dynamic Host Configuration Protocol (DHCP) server, whose
role is to assign IP addresses to devices.

**** DNS
- Domain Name System (DNS) exists to help us translate IP addresses
  to more memorable names that are more human-comprehensible.

|              IP | URI               |
|-----------------+-------------------|
|         0.0.0.0 | foo.com           |
|         0.0.0.1 | bar.ca            |
|                 |                   |
|     ...MORE IPs | ...MORE ADDRESSES |
|                 |                   |
| 255.255.255.254 | biblityboo.ir     |
| 255.255.255.255 | bibxlityboo2.net  |

- Large DNS server systems (like Google's own) are more like
  aggregators, collecting smaller sets of DNS information and pooling
  them togethe, updaing frequently.
- DNS record sets are fairly decentralized.

**** Access Points
- Other than IPv6 (which is not common yet), one of teh ways to deal
  with IPv4 addressing problem is to start assigning multiple people
  to the same IP address.
- The IP address is assigned to a /router/, whose job is to act as a
  traffic cop that allows data requests from all of the devices on
  that network to be processed through a single IP address.


*** IP
- "the Internet" is an /interconnected network/ comprised of smaller
  networks woven together and agreeing to communicate with one
  another.
- How do these networks know how to communicate with one another? This
  is the responsibility of the Internet Protocol(IP).
- Since we can't wire all those small networks together, we use *routers*.
- Instead of being connected to every other network, each network is
  connected to a limited number of routers (each of which is connected
  to other nearby routers), and each router has instructions (routing
  table) to where to send a /packet/ with a certain IP address. So not
  all those small networks have to physically connect to each
  other. It's somehow similar to recursion in programming. Reaching to
  destination one step at (one router) at a time.
  + So networks are not directly connected to each other at all (??),
    and rely on routers to distribute communications.
  + On a small scale, this configuration may actually be more
    inefficient than just having direct connections.
  + But on a large scale, this reduces the costs of network
    infrastructure.
- The data isn't being sent as one huge block. that would throttle the
  network for all the other users. Hence comes the *packets*.
- As such, another crucial part of IP is splitting data into *packets*.
- IP is also know as a /connectionless/ protocol. There is not
  necessarily a defined path from the sender to the receiver, and vice
  versa.
- This means that in response to traffic that might be "clogging" up
  one paricular path through the Internet, some packets can be
  "re-routed" around the traffic jam to follow the most optimal path,
  based on the current state of the network.
- IP doesn't guaranty delivery (like in case a packet is dropped), for
  that we rely on [[TCP]].

*** TCP
Transmission Control Protocol

- If the Internet Protocol(IP) is thought of as the protocol for
  getting information from a sending machine to a receiving machine,
  then TCP can be thought of as directing the transmitted packet to
  the correct program on the receiving machine.
- It is important to be able to identify both where the receiver is
  and what the packet is for, so TCP and IP are almost an inseparable
  pair: TCP/IP
- Each program/utility/service on a machine is assigned a /port
  number/. Coupled with an IP address, we can now uniquely identify a
  specific program on a specific machine.
- The other thing that TCP is crucial for is /guaranteeing delivery/
  of packets, which IP alone does not do.
- TCP does this by including information about how many packets the
  receiver should expect to get, and in what order, and transmitting
  that information alongside the data.
- Some ports are so commonly used that they have been standardized
  across all computers.
|--------------------+-----|
| FTP(file transfer) |  21 |
| SMTP(e-mail)       |  25 |
| DNS                |  53 |
| HTTP               |  80 |
| HTTPS              | 443 |
|--------------------+-----|

- Steps of the TCP/IP process:
  1. When a program goes to send data, TCP breaks it into smaller
     chunks and communicates those packets to the computer's network
     software, adding a TCP layer onto the packet. (what port it
     should go, number and order of packets...)
  2. IP routes the individual packets from sender to receiver; this
     info is part of the IP layer surrounding the packet.
  3. When the destination computer gets the packet, TCP looks at the
     header to see which program it belongs to; and since the routes
     packets take may differ, TCP also must present those packets to
     the detination program in the proper order. If a packet is
     missing (say it has been dropped along the way), TCP requests the
     lost packet from the sender.

** Databases
** Basic Computing Principles
*** OO
** Programming Paradigms
*** MVC
Primary motivation is *security*.

**** Model
This is where important data (i.e database) for the site lives, and it
may be updated, referenced and such.

**** View
These are the pages the user sees when they are interacting with your
site, usually based on interaction with the Model.

**** Controller
This is where the so-called /business logic/ of you site lives. Users
may submit information to the controller, which will then decide what
to present to the user.

** Miscellaneous
*** Pointer (in C)
- Pointers provide an alternative way to pass data between functions.
- Memory (RAM) is basically a huge *array* of 8-bit wide bytes. So it provide random access just like Arrays.
- When we say 32/64bit system it means every address in memory is 32/64 bits long.
|--------------------------------+-------------------------------------------------------------|
| Data Type                      |                                              Size(in bytes) |
|--------------------------------+-------------------------------------------------------------|
| int                            |                                                           4 |
| char                           |                                                           1 |
| float                          |                                                           4 |
| double                         |                                                           8 |
| long long                      |                                                           8 |
| char*, int*, float*, whatever* | depends on being a 32 or 64 bit machine, it's either 4 or 8 |
|                                | since they are just addresses of memory                     |
|--------------------------------+-------------------------------------------------------------|

Side Note: [[https://en.wikipedia.org/wiki/Endianness][Endianness]]
- Pointers are just addresses to locations in memory where variables live.
#+BEGIN_SRC C
  int k;
  k = 5;
  int* pk = NULL;   /* pk says: you gonna find an int in the address that I'm goin' to hold (currenty NULL) */
  pk = &k;          /* read & as 'address of' */
  /* now *pk is 5. Here * is dereference operator we can read it as 'go to' */
#+END_SRC
=pk= holds the location of =k= in memory. =pk= will be something like =0x80C74820=.
- So a pointer is a data item whose value is a memory address.
-
*** Dynamic Memory Allocation
- We can use pointers to get access to a block of *dynamically-alocated memory* at runtime.
- Dynamically allocated memory comes from a pool of memory known as
  the *heap* (that is to say it's not from *[[Stack]]*)
- In C
  + We get this dynamically-allocated memory by making a call to the C
    standard library function =malloc(needed_size)=, passing as its parameter the
    number of bytes requested.
  + After obtaining memory (if it can), =malloc= will return a pointer
    to that memory (or NULL if it was not able to).
#+BEGIN_SRC C
  // statically obtain an integer
  int x;

  // dynamically obtain an interger
  int *px = malloc(sizeof(int));

  // array of floats on the Stack
  float in_stack_array[X];

  // array of floats on the heap
  float* heap_array = malloc(x * sizeof(float));
#+END_SRC
- The Big Problem:
  + Dynamically-allocated memory is not automatically returned to the
    system for later use when function in which it's created finishes
    execution.
  + Failing to return memory back to the system when you're finished
    with it result in a *memory leak* which can compromise you
    system's performance.
  + When you finish working with dynamically-allocated memory, you must =free()= it.
#+BEGIN_SRC C
  char* word = malloc(50 * sizeof(char));
  /* do stuff with word */

  /* Now we're done. */
  free(word);
#+END_SRC
Another example
#+BEGIN_SRC C
  #include <stdio.h>
  #include <stdlib.h>

  int main (void) {
    int* b = malloc(sizeof(int));
    ,*b = 99;
    printf("%d\n", *b);          /* some serious stuff  */
    free(b);                     /* let it go */

    return 0;
  }
#+END_SRC

*** Compilers
**** Preprocessing
- In c, lines beginning with =#= are preprocessor directives.
- Using =clang=, =-E= flag only runs the preprocessor.
- It simply copy and pastes stuff in, say =#include <stdio.h>= to our source file.
**** Compilation
- Transforming from one language to another is compiling.
- Using =clang=, =-S= flag, compiles =C= to =assembly=.
**** Assembling
Transforming assembly code to machine code (Object code? what is it?).
- Using =clang=, =-c= flag, compiles =assembly= to machine code (e.g. =clang -c foo.s= it outputs =foo.o=)
**** Linking
???
*** Call Stack
- When we call a function, the system sets aside space in memory for
  that function to do its necessary work.
  + We call such chunks of memory *stack frames* or *function frames*
- More than one function's stack frame may exist in memory at a given
  time.
- More than one function's can have open frame but only one function
  can have active frame.
- These frames are arranged in a *stack*. The frame for the
  most-recently called function is always on the top of the stack.
- When a new function is called, a new frame is pushed onto the top of
  the stack and becomes the active frame.
- When a function finishes its work, its frame is popped off of the
  stack, and the frame immediately below it becomes the new, active,
  function on the top of the stack. The function picks up immediately
  where it left off.
** Tips
From [[https://github.com/kennyyu/workshop][this workshop]]:

- Think out loud
- Repeat the question
- Make sure you understand the problem by working through a few small
  and simple test cases. This will give you time to think and get some
  intuition on the problem. Your test cases should cover all normal
  and boundary cases(null, negatives, fractions, zero, empty, etc.)
- Write down function header/interface/calss def first and validate it
  with you interviewer to make sure you understand the problem first.
- Don't get frustrated.
- Don't try to come up with the most efficient algorithm from the first go.
