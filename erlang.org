#+PROPERTY: header-args :exports code
My Erlang notes, From [[https://learnyousomeerlang.com/][Learn You Some Erlang for Great Good]] book,
[[http://erlang.org/doc/index.html][official doc]], some talks on youtube and my own clarifications.

* Miscellaneous
- to get the documentation on lists =erl -man lists=
- [[http://www.erlang.se/doc/programming_rules.shtml][Programming Rules and Conventions]]
- Erlang functions and expressions must always return something.
- command line
  #+BEGIN_SRC sh
   $ erlc road.erl
   $ erl -noshell -run road main road.txt  # `main` is the main function, road.txt is the passing arg, road is the name file/module
  #+END_SRC
- =ERL_LIBS= The =ERL_LIBS= variable is a special variable defined in
  your environment that lets you specify where Erlang can find OTP
  applications. The VM is then able to automatically look in there to
  find the =ebin/= directories for you.
- =erl -env NameOFVar Value=
- =erl -AppName Key1 Val1 Key2 Val2 ... KeyN ValN=

* Basics
** Numbers
If you want to express integers in other bases than base 10, just
enter the number as Base#Value (given Base is in the range 2..36):
#+BEGIN_SRC erlang
> 2#101010.
42
#+END_SRC
** Atoms
An atom is referred to in an "atom table" which consumes memory (4
bytes/atom in a 32-bit system, 8 bytes/atom in a 64-bit system). The
atom table is not garbage collected, and so atoms will accumulate
until the system tips over, either from memory usage or because
1048577 atoms were declared.
#+BEGIN_SRC erlang
> atom = 'atom'.
atom
#+END_SRC
** Boolean Algebra & Comparison operators
the boolean operators =and= and =or= will always evaluate arguments on
both sides of the operator. If you want to have the short-circuit
operators (which will only evaluate the right-side argument if it
needs to), use =andalso= and =orelse=.

#+BEGIN_SRC
erl> 5 =:= 5.
true

erl> 1 =:= 0.
false

erl> 1 =/= 0.
true

erl> 5 =:= 5.0.
false

erl> 5 == 5.0.
true

erl> 5 /= 5.0.
false

erl> 1 >= 1.
true

erl> 1 =< 1.
true

erl> 0 == false.
false

erl> 1 < false.
true
#+END_SRC

Note: The correct ordering of each element in a comparison is the following:
=number < atom < reference < fun < port < pid < tuple < list < bit string=

Erlang has no such things as boolean true and false. The terms =true=
and =false= are atoms,
** Tuples
A tuple which contains an atom with one element following it is called
a 'tagged tuple'
** Lists
Strings are lists and the notation is the same!
#+BEGIN_SRC
erl> [97, 98, 99].
"abc"
#+END_SRC

Both =++= and =--= are right-associative. This means the elements of
many =--= or =++= operations will be done from right to left, as in the
following examples:
#+BEGIN_SRC
erl> [1,2,3] -- [1,2] -- [3].
[3]

erl> [1,2,3] -- [1,2] -- [2].
[2,3]
#+END_SRC
*** cons
These are all equivalent:
#+BEGIN_SRC
[a, b, c, d]
[a, b, c, d | []]
[a, b | [c, d]]
[a, b | [c | [d]]]
[a | [b | [c | [d]]]]
[a | [b | [c | [d | [] ]]]]
#+END_SRC
*** List Comprehensions
Set notation basically tells you how to build a set by specifying
properties its members must satisfy.

#+BEGIN_SRC
erl> [2*N || N <- [1,2,3,4]].
[2,4,6,8]

elr> [X*2 || X <- [1,2,3,4,5,6,7,8,9,10], X >= 4, X < 8].
[8,10,12,14]
#+END_SRC

#+BEGIN_SRC
NewList = [Expression || GeneratorExp1, GeneratorExp2, ..., GeneratorExpN, Condition1, Condition2, ... ConditionM]
#+END_SRC
** bit syntax
#+BEGIN_SRC  erlang
erl> Pixels = <<213,45,132, 64,76,32, 76,0,0, 234,32,15>>. % declare 4 pixels of RGB colors in binary
<<213,45,132,64,76,32,76,0,0,234,32,15>>

erl> <<Pix1,Pix2,Pix3,Pix4>> = Pixels. %  we have more than 4 segments
  exception error: no match of right hand side value <<213,45,132,64,76,32,76, 0,0,234,32,15>>

erl> 19> <<Foo,_,_,_,_,_,_,_,_,_,_,_>> = Pixels.
<<213,45,132,64,76,32,76,0,0,234,32,15>>

erl> Foo.
213

% We tell Erlang that each variable on the left side will hold 24 bits of data. That's what Var:24 means
erl> <<Pix1:24, Pix2:24, Pix3:24, Pix4:24>> = Pixels.
<<213,45,132,64,76,32,76,0,0,234,32,15>>

erl> <<R:8, G:8, B:8>> = <<Pix1:24>>.
<<213,45,132>>

7> R.
213

8> <<R:8, Rest/binary>> = Pixels.
<<213,45,132,64,76,32,76,0,0,234,32,15>>

9> R.
213
#+END_SRC

 Erlang accepts more than one way to describe a binary segment. Those are all valid:

    Value
    Value:Size
    Value/TypeSpecifierList
    Value:Size/TypeSpecifierList

where /Size/ is going to represent bits or bytes (depending on /Type/ and
/Unit/ below), and /TypeSpecifierList/ represents one or more of the
following:

- *Type*
    + Possible values: =integer= | =float= | =binary= | =bytes= |
      =bitstring= | =bits= | =utf8= | =utf16= | =utf32=
    + This represents the kind of binary data used. Note that 'bytes'
      is shorthand for 'binary' and 'bits' is shorthand for
      'bitstring'. When no type is specified, Erlang assumes an
      'integer' type.

- *Signedness*
  + Possible values: =signed= | =unsigned=
  + Only matters for matching when the type is integer. The default is
  'unsigned'.

- *Endianness*
  + Possible values: =big= | =little= | =native=

  + Endianness only matters when the Type is either integer, utf16,
  utf32, or float. This has to do with how the system reads binary
  data. As an example, the BMP image header format holds the size of
  its file as an integer stored on 4 bytes. For a file that has a size
  of 72 bytes, a little-endian system would represent this as
  <<72,0,0,0>> and a big-endian one as <<0,0,0,72>>. One will be read
  as '72' while the other will be read as '1207959552', so make sure
  you use the right endianness. There is also the option to use
  'native', which will choose at run-time if the CPU uses
  little-endianness or big-endianness natively. By default, endianness
  is set to 'big'.

- *Unit*
    + written unit:Integer

    + This is the size of each segment, in bits. The allowed range is
      1..256 and is set by default to 1 for integers, floats and bit
      strings and to 8 for binary. The utf8, utf16 and utf32 types
      require no unit to be defined. The multiplication of Size by
      Unit is equal to the number of bits the segment will take and
      must be evenly divisible by 8. The unit size is usually used to
      ensure byte-alignment.

The /TypeSpecifierList/ is built by separating attributes by a '-'.

#+BEGIN_SRC
erl> <<X1/unsigned>> =  <<-44>>.
<<"Ô">>

erl> X1.
212

erl> <<X2/signed>> =  <<-44>>.
<<"Ô">>

erl> X2.
-44

erl> <<X2/integer-signed-little>> =  <<-44>>.
<<"Ô">>

erl> X2.
-44

erl> <<N:8/unit:1>> = <<72>>.
<<"H">>

erl> N.
72

erl> <<N/integer>> = <<72>>.
<<"H">>

erl> <<Y:4/little-unit:8>> = <<72,0,0,0>>.
<<72,0,0,0>>

erl> Y.
72
#+END_SRC



The standard binary operations (shifting bits to left and right,
binary 'and', 'or', 'xor', or 'not') also exist in Erlang. Just use
the functions =bsl= (Bit Shift Left), =bsr= (Bit Shift Right), =band=, =bor=,
=bxor=, and =bnot=.

#+BEGIN_SRC
2#00100 = 2#00010 bsl 1.
2#00001 = 2#00010 bsr 1.
2#10101 = 2#10001 bor 2#00101.
#+END_SRC

Example: parse TCP segments
#+BEGIN_SRC
<<SourcePort:16, DestinationPort:16,
AckNumber:32,
DataOffset:4, _Reserved:4, Flags:8, WindowSize:16,
CheckSum: 16, UrgentPointer:16,
Payload/binary>> = SomeBinary.
#+END_SRC

*** bit strings
#+BEGIN_SRC
<<"this is a bit string!">>
#+END_SRC

** Binary Comprehensions
#+BEGIN_SRC
erl> [ X || <<X>> <= <<1,2,3,4,5>>, X rem 2 == 0].
[2,4]

2> Pixels = <<213,45,132,64,76,32,76,0,0,234,32,15>>.
<<213,45,132,64,76,32,76,0,0,234,32,15>>

3> RGB = [ {R,G,B} || <<R:8,G:8,B:8>> <= Pixels ].
[{213,45,132},{64,76,32},{76,0,0},{234,32,15}]

erl> RGB.
[{213,45,132},{64,76,32},{76,0,0},{234,32,15}]

erl> << <<R:8, G:8, B:8>> ||  {R,G,B} <- RGB >>.
<<213,45,132,64,76,32,76,0,0,234,32,15>>

erl> << <<(X+1)/integer>> || <<X>> <= <<3,7,5,4,7>> >>.
<<4,8,6,5,8>>
#+END_SRC
* Modules
- All functions in Erlang must be defined in modules.
- module attributes are metadata describing the module itself. They can be found via =module_info/0=, like =mymod.module_info().=
- =-module(Name).=  This is always the first attribute (and statement) of
  a file, and for good reason: it's the name of the current module,
  where Name is an atom. This is the name you'll use to call
  functions from other modules. The calls are made with the =M:F(A)=
  form, where =M= is the module name, =F= the function, and A the
  arguments.
- =-export([Function1/Arity, Function2/Arity, ..., FunctionN/Arity]).=
- =-import(Module, [Function1/Arity, ..., FunctionN/Arity]).=
  Importing a function is not much more than a shortcut
- =-define(MACRO, some_value).=
  e.g =-define(foo, 88).= and to use it =?foo=
  e.g =-define(sub(X,Y), X-Y).= and to use it =?sub(23,47)=

* Compiling the code
  - =erlc flags file.erl= when in the command line
  - =compile:file(FileName)= when in the shell or in a module
  - =c()= when in the shell
*** flags
    - =-debug_info=
    - =-{outdir,Dir}=
    - =-export_all=: Will ignore the =-export= module attribute
   - =-{d,Macro}= or ={d,Macro,Value}= Defines a macro to be used in
     the module, where Macro is an atom. This is more frequently used
     when dealing when unit-testing, ensuring that a module will only
     have its testing functions created and exported when they are
     explicitly wanted. By default, Value is 'true' if it's not
     defined as the third element of the tuple.

e.g.
#+BEGIN_SRC
erl> compile:file(useless, [debug_info, export_all]).
{ok,useless}

erl> c(useless, [debug_info, export_all]).
{ok,useless}
#+END_SRC

Compiler flags can also be defined from within a module, with a module
attribute.
#+BEGIN_SRC erlang
-compile(export_all).
#+END_SRC

You could also use =c(Module,[native])=.
* Pattern Matching
Get the second element of a list
#+BEGIN_SRC erlang
second([_, X|_]) ->
    X.

same(X,X) ->
    true;
same(_,_) ->
    false.

foo({First = {X,Y,Z}, Second = {H, S, M}}) ->
    io:format("X:~p, Y: ~p, Z: ~p, H: ~p, S: ~p, M: ~p~n", [X,Y,Z, H, S, M]),
    io:format("First: ~p, second: ~p~n", [First, Second]).
#+END_SRC
* Guards, Guards!
#+BEGIN_SRC erlang
old_enough(X) when X >= 16 -> true;
old_enough(_) -> false.

right_age(X) when X >= 16, X =< 104 -> %% The comma (,) acts in a similar manner to the operator `andalso`
    true;
right_age(_) ->
    false.

wrong_age(X) when X < 16; X > 104 -> %% the semicolon (;) acts a bit like `orelse`
    true;
wrong_age(_) ->
    false.
#+END_SRC

Note: I've compared =,= and =;= in guards to the operators =andalso= and
=orelse=. They're not exactly the same, though. The former pair will
catch exceptions as they happen while the latter won't. What this
means is that if there is an error thrown in the first part of the
guard `X >= N; N >= 0`, the second part can still be evaluated and the
guard might succeed; if an error was thrown in the first part of `X >= N orelse N >= 0`,
the second part will also be skipped and the whole
guard will fail.

However, only =andalso= and =orelse= can be
nested inside guards. This means =(A orelse B) andalso C= is a valid
guard, while =(A; B), C= is not.



Note: type test BIFs constitute more than half of the functions
allowed in guard expressions. The rest are also BIFs, but do not
represent type tests. These are:

#+BEGIN_SRC erlang
 abs(Number), bit_size(Bitstring), byte_size(Bitstring), element(N, Tuple),
 float(Term), hd(List), length(List), node(),
 node(Pid|Ref|Port), round(Number), self(), size(Tuple|Bitstring),
 tl(List), trunc(Number), tuple_size(Tuple)
#+END_SRC

e.g
#+BEGIN_SRC erlang
zip(Xs, Ys) when length(Xs) == length(Ys) ->
    lists:reverse(zip(Xs, Ys, [])).

zip([], [], Result) ->
    Result;
zip([X|Xs], [Y|Ys], Result) ->
    zip(Xs, Ys, [{X, Y} | Result]).
#+END_SRC

* if
The =if= clauses are called Guard Patterns.

#+BEGIN_SRC erlang
  oh_god(N) ->
      if N =:= 2 -> might_succeed;
         true -> always_does  %% this is Erlang's if's 'else!', we can't omit this, or else we get an error
      end.

  help_me(Animal) ->
      Talk = if Animal == cat ->
                     "meow";
                Animal == beef ->
                     "moo";
                Animal == dog ->
                     "bark";
                true ->
                     "fdlkajfj"
             end,
      {Animal, "says " ++ Talk ++ "!"}.
#+END_SRC
* In Case ... of
a =case ... of= expression is like the whole function head: you can
have the complex pattern matching you can use with each argument, and
you can have guards on top of it!

#+BEGIN_SRC erlang
  insert(X, []) ->
      [X];
  insert(X, Set) ->
      case lists:member(X, Set) of
          true -> Set;
          false -> [X | Set]
      end.

  beach(Temperature) ->
      case Temperature of
          {celsius, N} when N >= 20, N =< 45 ->
              'favorable';
          {kelvin, N} when N >= 293, N =< 318 ->
              'scientifically favorable';
          {fahrenheit, N} when N >= 68, N =< 113 ->
              'favorable in the US';
          _ ->
              'avoid beach'
      end.
#+END_SRC

* Type conversions
Each of these functions take the form =<type>_to_<type>= and are
implemented in the =erlang= module.
#+BEGIN_SRC
1> erlang:list_to_integer("54").
54

2> erlang:integer_to_list(54).
"54"

3> erlang:list_to_integer("54.32").
   exception error: bad argument
in function  list_to_integer/1
called as list_to_integer("54.32")

4> erlang:list_to_float("54.32").
54.32

5> erlang:atom_to_list(true).
"true"

6> erlang:list_to_bitstring("hi there").
<<"hi there">>

7> erlang:bitstring_to_list(<<"hi there">>).
"hi there"
#+END_SRC

All of them:
#+BEGIN_SRC
atom_to_binary/2, atom_to_list/1, binary_to_atom/2,
binary_to_existing_atom/2, binary_to_list/1, bitstring_to_list/1,
binary_to_term/1, float_to_list/1, fun_to_list/1, integer_to_list/1,
integer_to_list/2, iolist_to_binary/1, iolist_to_atom/1,
list_to_atom/1, list_to_binary/1, list_to_bitstring/1,
list_to_existing_atom/1, list_to_float/1, list_to_integer/2,
list_to_pid/1, list_to_tuple/1, pid_to_list/1, port_to_list/1,
ref_to_list/1, term_to_binary/1, term_to_binary/2, tuple_to_list/1.
#+END_SRC
* To Guard a Data Type
type test BIFs:
#+BEGIN_SRC
is_atom/1           is_binary/1
is_bitstring/1      is_boolean/1        is_builtin/3
is_float/1          is_function/1       is_function/2
is_integer/1        is_list/1           is_number/1
is_pid/1            is_port/1           is_record/2
is_record/3         is_reference/1      is_tuple/1
#+END_SRC
* types
** =dialyzer=
** =typer=

* Recursion
#+BEGIN_SRC erlang
tail_fac(N) ->
    tail_fac(N, 1).

tail_fac(0, Acc) ->
    Acc;
tail_fac(N, Acc) when N > 0 ->
    tail_fac(N - 1, Acc * N).

zip([],_) -> [];
zip(_,[]) -> [];
zip([X|Xs],[Y|Ys]) -> [{X,Y}|zip(Xs,Ys)].


qSort([]) ->
    [];
qSort(L) when is_list(L) ->
    qSort(L, []).

qSort([], Acc) ->
    Acc;
qSort([Pivot|Rest], Acc) ->
    partition(Pivot, Rest, {[], [Pivot], []}, Acc).

partition(_Pivot, [], {Smaller, Equal, Bigger}, Acc) ->
    qSort(Smaller, Equal ++ qSort(Bigger, Acc));

partition(Pivot, [H | T], {Smaller, Equal, Bigger}, Acc) ->
    if H > Pivot -> partition(Pivot, T, {Smaller, Equal, [H | Bigger]}, Acc);
       H < Pivot -> partition(Pivot, T, {[H | Smaller], Equal, Bigger}, Acc);
       H =:= Pivot -> partition(Pivot, T, {Smaller, [H | Equal], Bigger}, Acc)
    end.
#+END_SRC

Note: tail recursion as seen here is not making the memory grow
because when the virtual machine sees a function calling itself in a
tail position (the last expression to be evaluated in a function), it
eliminates the current stack frame. This is called tail-call
optimisation (TCO) and it is a special case of a more general
optimisation named Last Call Optimisation (LCO).

LCO is done whenever the last expression to be evaluated in a function
body is another function call. When that happens, as with TCO, the
Erlang VM avoids storing the stack frame. As such tail recursion is
also possible between multiple functions. As an example, the chain of
functions =a() -> b(). b() -> c(). c() -> a().= will effectively create
an infinite loop that won't go out of memory as LCO avoids overflowing
the stack. This principle, combined with our use of accumulators is
what makes tail recursion useful.

* Higher Order Functions

#+BEGIN_SRC erlang
-module(hhfuns).
-compile(export_all).

one() ->
    1.
two() ->
    2.

add(X, Y) ->
    X() + Y().

%% to call it `hhfuns:add(fun hhfuns:one/0, fun hhfuns:two/0).`
#+END_SRC

* Anonymous functions
- syntax
    #+BEGIN_SRC erlang
fun(Args1) ->
        Expression1, Exp2, ..., ExpN;
   (Args2) ->
        Expression1, Exp2, ..., ExpN;
   (Args3) ->
        Expression1, Exp2, ..., ExpN
end
#+END_SRC
    e.g
    #+BEGIN_SRC erlang
fun(A,B) when A > B -> A; (_,B) -> B end
#+END_SRC
- You're most likely to use anonymous functions to carry state around
- define and call immediately
  #+BEGIN_SRC erlang
  (fun(X) -> io:format("It's ~p~n", [X]) end)(42).
  #+END_SRC
- name 'em
    the name is visible only within the function's scope
    #+BEGIN_SRC erlang
     fun Loop() ->
        io:format("I'm loop~n"),
        timer:sleep(500),
         Loop()  %% <------- calling itself
     end
    #+END_SRC
- look at =fold= beauty
  #+BEGIN_SRC erlang
    fold(_, Start, []) -> Start;
    fold(F, Start, [H|T]) -> fold(F, F(H,Start), T).


    reverse(L) ->
        fold(fun(X,Acc) -> [X|Acc] end, [], L).

    map(F,L) ->
        reverse(fold(fun(X,Acc) -> [F(X)|Acc] end, [], L)).

    filter(Pred, L) ->
        F = fun(X,Acc) ->
                    case Pred(X) of
                        true  -> [X|Acc];
                        false -> Acc
                    end
            end,
        reverse(fold(F, [], L)).
  #+END_SRC
* Errors
By default, Erlang's search path is set to be in the current
directory. You can add paths by using =code:add_patha/1= or
=code:add_pathz/1=.

Calling =erlang:error(Reason)= will end the execution in the current process.
#+BEGIN_SRC
1> erlang:error(badarith).
 exception error: bad argument in an arithmetic expression

2> erlang:error(custom_error).
 exception error: custom_error
#+END_SRC
* Exits
- There are two kinds of exits: 'internal' exits and 'external' exits.
- Internal exits are triggered by calling the function =exit/1= and
  make the current process stop its execution.
- External exits are called with =exit/2=
- =erlang:error/1= returns a stack trace and =exit/1= doesn't
* Throws
A throw is a class of exceptions used for cases that the programmer
can be expected to handle.

In comparison with exits and errors, they don't really carry any
'crash that process!' intent behind them, but rather control flow.

#+BEGIN_SRC
1> throw(permission_denied).
 exception throw: permission_denied
#+END_SRC

Usecase: An example could be the array module, where there is a
lookup function that can return a user-supplied default value if it
can't find the element needed. When the element can't be found, the
value default is thrown as an exception, and the top-level function
handles that and substitutes it with the user-supplied default
value. This keeps the programmer of the module from needing to pass
the default value as a parameter of every function of the lookup
algorithm, again focusing only on the successful cases.

e.g
#+BEGIN_SRC erlang
  %% looks for a given value 'Val' in the tree.
  has_value(_, {node, 'nil'}) ->
      false;
  has_value(Val, {node, {_, Val, _, _}}) ->
      true;
  has_value(Val, {node, {_, _, Left, Right}}) ->
      case has_value(Val, Left) of
          true -> true;
          false -> has_value(Val, Right)
      end.

  %% -------------------- using throw --------------------
  has_value(Val, Tree) ->
      try has_value1(Val, Tree) of
          false -> false
      catch
          true -> true
      end.

  has_value1(_, {node, 'nil'}) ->
      false;
  has_value1(Val, {node, {_, Val, _, _}}) ->
      throw(true);
  has_value1(Val, {node, {_, _, Left, Right}}) ->
      has_value1(Val, Left),
      has_value1(Val, Right).
#+END_SRC

* Dealing with Exceptions
- The Expression in between try and of is said to be protected.
- Note: It is important to know that the protected part of an
  exception can't be tail recursive. The VM must always keep a
  reference there in case there's an exception popping up.
- Because the =try ... catch= construct without the =of= part has nothing
  but a protected part, calling a recursive function from there might
  be dangerous for programs supposed to run for a long time (which is
  Erlang's niche). After enough iterations, you'll go out of memory or
  your program will get slower without really knowing why. By putting
  your recursive calls between the =of= and =catch=, you are not in a
  protected part and you will benefit from Last Call Optimisation.

You can replace =TypeOfError= by either =error=, =throw= or =exit=.
#+BEGIN_SRC erlang
  try Expression of
      SuccessfulPattern1 [Guards] ->
          Expression1;
      SuccessfulPattern2 [Guards] ->
          Expression2
  catch
      TypeOfError:ExceptionPattern1 ->
          Expression3;
      TypeOfError:ExceptionPattern2 ->
          Expression4
  end.
#+END_SRC
#+BEGIN_SRC erlang
-module(errors).
-compile(export_all).

%% foo() -> exit(foobar).
foo() -> erlang:error(badarith).

bar() ->
    try foo() of
        _ -> io:format("all good")
    catch
        error:badarith -> io:format("you DON'T know math.~n");
        error:Shit -> io:format("error -> ~p~n", [Shit]);
        throw:Shit -> io:format("throw -> ~p~n", [Shit]);
        exit:Shit -> io:format("exit -> ~p~n", [Shit])
    end.
#+END_SRC

- it's possible to have more than one expression between the =try= and the =of=
    #+BEGIN_SRC erlang
      whoa() ->
          try
              talk(),
              _Knight = "None shall Pass!",
              _Doubles = [N*2 || N <- lists:seq(1,100)],
              throw(up),
              _WillReturnThis = tequila
          of
              tequila -> "hey this worked!"
          catch
              Exception:Reason -> {caught, Exception, Reason}
          end.
    #+END_SRC
- it's possible to omit =of= part
    #+BEGIN_SRC erlang
      im_impressed() ->
          try
              talk(),
              _Knight = "None shall Pass!",
              _Doubles = [N*2 || N <- lists:seq(1,100)],
              throw(up),
              _WillReturnThis = tequila
          catch
              Exception:Reason -> {caught, Exception, Reason}
          end.
    #+END_SRC

** after
#+BEGIN_SRC erlang
  try Expr of
      Pattern -> Expr1
  catch
      Type:Exception -> Expr2
  after % this always gets executed
      Expr3
  end
#+END_SRC
 You can NOT get any return value out of the =after=
 construct. Therefore, =after= is mostly used to run code with side
 effects. The canonical use of this is when you want to make sure a
 file you were reading gets closed whether exceptions are raised or
 not.
** catch
#+BEGIN_SRC
erl> catch throw(whoa).
whoa

erl> catch exit(die).
{'EXIT',die}

erl> catch 1/0.
{'EXIT',{badarith,[{erlang,'/',[1,0]},
                   {erl_eval,do_apply,5},
                   {erl_eval,expr,5},
                   {shell,exprs,6},
                   {shell,eval_exprs,6},
                   {shell,eval_loop,3}]}}

erl> catch 2+2.
4
#+END_SRC

#+BEGIN_SRC erlang
  catcher(X,Y) ->
      case catch X/Y of
          {'EXIT', {badarith,_}} -> "uh oh";
          N -> N
      end.
#+END_SRC
* Records
Records are, first of all, a hack. Erlang records are just syntactic
sugar on top of tuples.

#+BEGIN_SRC erlang
  -module(records).
  -compile(export_all).

  -record(robot, {name,
                  type=industrial,
                  hobbies,
                  details=[]}).

  first_robot() ->
      #robot{name="Mechatron",
             type=handmade,
            details=["Moved by a small man inside"]}. %% hobbies will be undefined
#+END_SRC
#+BEGIN_SRC
1> c(records).
{ok,records}

2> records:first_robot().
{robot,"Mechatron",handmade,undefined,
["Moved by a small man inside"]}

3> rr(records).
[robot]

4> records:first_robot().
#robot{name = "Mechatron",type = handmade,
hobbies = undefined,
details = ["Moved by a small man inside"]}

5> Crusher = #robot{name="Crusher", hobbies=["Crushing people","petting cats"]}.
#robot{name = "Crusher",type = industrial,
hobbies = ["Crushing people","petting cats"],
details = []}

6> Crusher#robot.hobbies.
["Crushing people","petting cats"]


erl> Fuck = #robot{details=#robot{type="shitty"}}.
#robot{name = undefined,type = industrial,
       hobbies = undefined,
       details = #robot{name = undefined,type = "shitty",
                        hobbies = undefined,details = []}}

erl> Fuck#robot.details#robot.type.
"shitty"

erl> #robot.type. %% What this outputs is which element of the underlying tuple it is.
3
#+END_SRC

- Pattern Matching
  #+BEGIN_SRC erlang
    -record(user, {id, name, group, age}).

    admin_panel(#user{name=Name, group=admin}) ->
        Name ++ " is allowed!";
    admin_panel(#user{name=Name}) ->
        Name ++ " is not allowed".

    adult_section(U = #user{}) when U#user.age >= 18 ->
        allowed;

    adult_section(_) ->
        forbidden.
  #+END_SRC
- Update a record
  #+BEGIN_SRC
    erl> Me = #user{age=26}.
    #user{id = undefined,name = undefined,group = undefined, age = 26}
                                                                age = 27}
    erl> MeOlder = #user{age=Me#user.age + 1}.
    #user{id = undefined,name = undefined,group = undefined, age = 27}

    erl> MeOlder#user.age.
    27
  #+END_SRC

- share records across modules with the help of header files.
  Erlang header files are pretty similar to their C counter-part:
  they're nothing but a snippet of code that gets added to the module
  as if it were written there in the first place.
  #+BEGIN_SRC erlang
    %% this is a .hrl (header) file.
    -record(included, {some_field,
                       some_default = "yeah!",
                       unimaginative_name}).
  #+END_SRC
  To include it in a module, just add the following line to the module:
  #+BEGIN_SRC erlang
    -include("records.hrl").

    %% use it as usual
    included() -> #included{some_field="Some value"}.
  #+END_SRC

* Data Structures
** proplist
A proplist is any list of tuples of the form =[{Key,Value}]=.
To work with proplists, you can use the =proplists= module.

** orddict
If you do want a more complete key-value store for small amounts of
data, the =orddict= module is what you need. Orddicts (ordered
dictionaries) are proplists with a taste for formality. Each key can
be there once, the whole list is sorted for faster average lookup,
etc.

Orddicts are a generally good compromise between complexity and
efficiency up to about 75 elements. After that amount, you should
switch to different key-value stores.

** =dicts=, =gb_trees= and =maps=
These are basically key-value structures/modules to deal with
larger amounts of data.

** =arrays=
Erlang arrays, at the opposite of their imperative counterparts, are
not able to have such things as constant-time insertion or
lookup. Because they're usually slower than those in languages which
support destructive assignment and that the style of programming done
with Erlang doesn't necessary lend itself too well to arrays and
matrices, they are rarely used in practice.  Generally, Erlang
programmers who need to do matrix manipulations and other uses
requiring arrays tend to use concepts called Ports to let other
languages do the heavy lifting, or C-Nodes, Linked in drivers and NIFs
(Experimental, R13B03+).

** Sets
There are 4 main modules to deal with sets in Erlang. This is a bit
weird at first, but it makes more sense once you realize that it's
because it was agreed by implementers that there was no 'best' way to
build a set. The four modules are =ordsets=, =sets=, =gb_sets= and =sofs=
(sets of sets):

- =ordsets=: Ordsets are implemented as a sorted list. They're mainly
  useful for small sets, are the slowest kind of set, but they have
  the simplest and most readable representation of all sets. There are
  standard functions for them such as =ordsets:new/0=,
  =ordsets:is_element/2=, =ordsets:add_element/2=, =ordsets:del_element/2=,
  =ordsets:union/1=, =ordsets:intersection/1=, and a bunch more.

- =sets=: Sets (the module) is implemented on top of a structure really
  similar to the one used in dict. They implement the same interface
  as ordsets, but they're going to scale much better. Like
  dictionaries, they're especially good for read-intensive
  manipulations, like checking whether some element is part of the set
  or not.

- =gb_sets=: =Gb_sets= themselves are constructed above a General
  Balanced Tree structure similar to the one used in the =gb_trees=
  module. =gb_sets= are to =sets= what =gb_tree= is to =dict=; an
  implementation that is faster when considering operations different
  than reading, leaving you with more control. While =gb_sets= implement
  the same interface as =sets= and =ordsets=, they also add more
  functions. Like =gb_trees=, you have smart vs. naive functions,
  iterators, quick access to the smallest and largest values, etc.

- =sofs= Sets of sets (sofs) are implemented with sorted lists, stuck
  inside a tuple with some metadata. They're the module to use if you
  want to have full control over relationships between sets, families,
  enforce set types, etc. They're really what you want if you need
  mathematics concept rather than 'just' groups of unique elements.

  :NOTE:
  Björn Gustavsson, from the Erlang/OTP team and programmer of Wings3D
  mainly suggests using gb_sets in most circumstances, using ordset when
  you need a clear representation that you want to process with your own
  code and 'sets' when you need the \=:= operator (source.)
  :END:

** directed graphs (=digraph= and =digraph_utils=)

*** =digraph=
basically allows the construction and modification of a directed
graph: manipulating edges and vertices, finding paths and cycles

*** =digraph_utils=
allows you to navigate a graph (postorder, preorder), testing for
 cycles, arborescences or trees, finding neighbors, and so on.

** Queues
* concurrency
- the main sources of downtime in large scale software systems are
  intermittent or transient bugs. [[http://dslab.epfl.ch/pubs/crashonly.pdf][Source]]
- Erlang's processes take about 300 words of memory each (in a 32-bit
  processor 4 byte and 8 byte in a 64-bit implementation. [[http://erlang.org/doc/efficiency_guide/advanced.html#id2265856][Memory]]) and
  can be created in a matter of microseconds.
- The VM starts one thread per core which acts as a scheduler. Each of
  these schedulers has a run queue, or a list of Erlang processes on
  which to spend a slice of time. When one of the schedulers has too
  many tasks in its run queue, some are migrated to another one. This
  is to say each Erlang VM takes care of doing all the load-balancing.
- About linear scaling:
  Amdahl's Law: It indicates how much of a speedup you can expect your
  system to have whenever you add parallelism to it, and in what
  proportion. According to Amdahl's law, code that is 50% parallel can
  never get faster than twice what it was before, and code that is 95%
  parallel can theoretically be expected to be about 20 times faster
  if you add enough processors.
- disabling symmetric multiprocessing =$ erl -smp disable= or =erl +S 1=
  in erl =[smp:2:2]= means there are two cores available, with two schedulers.

** =spawn=
#+BEGIN_SRC erlang
Pid_1 = spawn(fun() -> ... end)
Pid_2 = spawn(module, fun, [args])
#+END_SRC

** =!=
#+BEGIN_SRC
9> self() ! hello.
hello

10> self() ! self() ! double.
double
#+END_SRC
** =receive=
#+BEGIN_SRC erlang
receive
  Pattern1 when Guard1 -> Expr1;
  Pattern2 when Guard2 -> Expr2;
  Pattern3 -> Expr3
  after Delay -> Expression2
end
#+END_SRC
** =after=
two interesting use-case
#+BEGIN_SRC erlang
  sleep(T) ->
      receive
      after T -> ok
      end.

  flush() ->
      receive
          _ -> flush()
      after 0 ->
              ok
      end.
#+END_SRC
** Selective Receives
#+BEGIN_SRC erlang
  important() ->
      receive
          {Priority, Message} when Priority > 10 ->
              [Message | important()]
      after 0 ->                                  % every message will be obtained until none is left
              normal()
      end.

  normal() ->
      receive
          {_, Message} ->
              [Message | normal()]
      after 0 ->                                  % every message will be obtained until none is left
              []
      end.
#+END_SRC
- be aware that is is sometimes unsafe due to the way selective
  receives work in Erlang.
- When messages are sent to a process, they're stored in the mailbox
  until the process reads them and they match a pattern there. As said
  in the previous chapter, the messages are stored in the order they
  were received. This means every time you match a message, it begins
  by the oldest one.

- That oldest message is then tried against every pattern of the
  receive until one of them matches. When it does, the message is
  removed from the mailbox and the code for the process executes
  normally until the next receive. When this next receive is
  evaluated, the VM will look for the oldest message currently in the
  mailbox (the one after the one we removed), and so on.

- When there is no way to match a given message, it is put in a save
  queue and the next message is tried. If the second message matches,
  the first message is put back on top of the mailbox to be retried
  later.
- This lets you only care about the messages that are useful. Ignoring
  some messages to handle them later. While they're useful, the
  problem with them is that if your process has a lot of messages you
  never care about, reading useful messages will actually take longer
  and longer (and the processes will grow in size too).

- =make_ref=
  #+BEGIN_SRC erlang
  optimized(Pid) ->
    Ref = make_ref(),
    Pid ! {self(), Ref, hello},
    receive
        {Pid, Ref, Msg} ->
            io:format("~p~n", [Msg])
    end.
  #+END_SRC
  Since R14A, a new optimization has been added to Erlang's
  compiler. It simplifies selective receives in very specific cases of
  back-and-forth communications between processes. To make it work, a
  reference (=make_ref()=) has to be created in a function and then sent
  in a message. In the same function, a selective receive is then
  made. If no message can match unless it contains the same reference,
  the compiler automatically makes sure the VM will skip messages
  received before the creation of that reference.
* Links
- A link is a specific kind of relationship that can be created
  between two processes. When that relationship is set up and one of
  the processes dies from an unexpected =throw=, =error= or =exit=,
  the other linked process also dies.

- This function will take an integer N, start N processes linked one
  to the other.
  #+BEGIN_SRC erlang
    chain(0) ->
        receive
            _ -> ok
        after 2000 ->
                exit("chain dies here")
        end;
    chain(N) ->
        Pid = spawn(fun() -> chain(N-1) end),
        link(Pid),
        receive
            _ -> ok
        end.
  #+END_SRC

- links are bidirectional
- To get rid of a =link=, use [[erldocs.com/18.0/erts/erlang.html#unlink/1][unlink/1]]
- Links can not be stacked. If you call =link/1= 15 times for the
  same two processes, only one link will still exist between them and
  a single call to =unlink/1= will be enough to tear it down.
- unlike =link(spawn(Function))= or =link(spawn(M,F,A))=,
  =spawn_link/1-3= is atomic.

* System processes
- System processes are basically normal processes, except they can
  convert exit signals to regular messages. This is done by calling
  =process_flag(trap_exit, true)= in a running process.
  #+BEGIN_SRC erlang
    erl> spawn_link(fun() -> exit("I'm dying already.") end).
     exception exit: "I'm dying already."

    erl> process_flag(trap_exit, true).
    false

    erl> spawn_link(fun() -> exit("I'm dying already.") end).
    <0.90.0>

    erl> flush().
    Shell got {'EXIT',<0.90.0>,"I'm dying already."}
    ok
  #+END_SRC
- By writing programs using system processes, it is easy to create a
  process whose only role is to check if something dies and then
  restart it whenever it fails.
- =exit/2=
* Monitors
- Monitors are a special type of link with two differences:
  1. they are unidirectional.
  2. they can be stacked.

- Monitors are what you want when a process wants to know what's going
  on with a second process, but neither of them really are vital to
  each other.

- =erlang:monitor/2=
  #+BEGIN_SRC erlang
    erl> Pid = spawn(fun() -> timer:sleep(5000) end).
    <0.90.0>

    erl>  erlang:monitor(process, Pid).
    #Ref<0.2327554241.1187774465.188331>

    erl>  erlang:monitor(process, Pid).
    #Ref<0.2327554241.1187774465.188336>

    erl> flush().
    Shell got {'DOWN',#Ref<0.2327554241.1187774465.188331>,process,<0.90.0>,
                      normal}
    Shell got {'DOWN',#Ref<0.2327554241.1187774465.188336>,process,<0.90.0>,
                      normal}
    ok
  #+END_SRC
- Every time a process you monitor goes down, you will receive such a
  message. The message is ={'DOWN', MonitorReference, process, Pid, Reason}=
- The /reference/ is there to allow you to demonitor the
  process. Remember, monitors are stackable, so it's possible to take
  more than one down. References allow you to track each of them in a
  unique manner.
- There is an atomic function to spawn a process while monitoring it,
  =spawn_monitor/1-3=

- =demonitor/1=
  #+BEGIN_SRC erlang
    erl> {Pid, Ref} = spawn_monitor(fun() -> receive _ -> exit(boom) end end).
    {<0.73.0>,#Ref<0.0.0.100>}

    erl> erlang:demonitor(Ref).
    true

    erl> Pid ! die.
    die

    erl> flush().
    ok
  #+END_SRC

* Naming Processes
- To give a process a name, the function =erlang:register/2= is used.
- If the process dies, it will automatically lose its name or you can
  also use =unregister/1= to do it manually.
- You can get a list of all registered processes with =registered/0= or
  a more detailed one with the shell command =regs()=.
- =whereis(foo)= is used to find the foo's process identifier
  #+BEGIN_SRC erlang
    -module(linkmon).
    -compile(export_all).

    start_critic() ->
        spawn(?MODULE, restarter, []).

    restarter() ->
        process_flag(trap_exit, true),
        Pid = spawn_link(?MODULE, critic, []),
        register(critic, Pid),
        receive
            {'EXIT', Pid, normal} ->
                ok;
            {'EXIT', Pid, _} ->
                restarter()
        end.


    judge(Band, Album) ->
        Ref = make_ref(),
        critic ! {self(), Ref, {Band, Album}},
        receive
            {Ref, Criticism} ->
                Criticism
        after 2000 ->
                timeout
        end.

    critic() ->
        receive
            {From, Ref, {"Johnny Crash", "The Token Ring of Fire"}} ->
                From ! {Ref, "Simply incredible."};
            {From, Ref, {_Band, _Album}} ->
                From ! {Ref, "They are terrible!"}
        end,
        critic().
  #+END_SRC
  #+BEGIN_SRC erlang
    erl> linkmon:start_critic().
    <0.85.0>

    erl> linkmon:judge("foo", "bar").
    "They are terrible!"

    erl> linkmon:judge("Johnny Crash", "The Token Ring of Fire").
    "Simply incredible."
  #+END_SRC

- You shouldn't ever create dynamic atoms. atoms can be used in a
  limited (though high) number.
* Designing a Concurrent Application
- If we monitor a process that doesn't exist (we won't notice that by
  just monitoring), then we send it a message we'll receive a message,
  something like
  ={'DOWN',#Ref<0.2588815752.2474377217.6021>,process,<0.134.9>,noproc}=.
  That's the reason for the second clause of the following receive. In
  case the process associated with Pid doesn't exist we get there.
  #+BEGIN_SRC erlang
    cancel(Pid) ->
        %% Monitor in case the process is already dead
        Ref = erlang:monitor(process, Pid),
        Pid ! {self(), Ref, cancel},
        receive
            {Ref, ok} ->
                erlang:demonitor(Ref, [flush]),
                ok;
            {'DOWN', Ref, process, Pid, _Reason} ->
                ok
        end.
  #+END_SRC

- Most messages will be wrapped under the form ={Pid, Ref, Message}=,
  where =Pid= is the sender and =Ref= is a unique message identifier to
  help know what reply came from who. If we were to send many messages
  before looking for replies, we would not know what reply went with
  what message without a reference.
* Hot Code Loving
- In order to do hot code loading, Erlang has a thing called the *code server*.
  The code server is basically a VM process in charge of an
  ETS table (in-memory database table, native to the VM.) The code
  server can hold two versions of a single module in memory, and both
  versions can run at once. A new version of a module is automatically
  loaded when compiling it with =c(Module)=, loading with =l(Module)= or
  loading it with one of the many functions of the [[http://erldocs.com/18.0/kernel/code.html][code module]].
- local calls: function calls you can make with functions that might
  not be exported. They're just of the format =Atom(Args)=.
- external call: can only be done with exported functions and has the
  form =Module:Function(Args)=

- When there are two versions of a module loaded in the VM, all local
  calls are done through the currently running version in a
  process. However, external calls are always done on the newest
  version of the code available in the code server. Then, if local
  calls are made from within the external one, they are in the new
  version of the code.
  #+BEGIN_SRC erlang
    -module(hotload).
    -export([server/1, upgrade/1]).

    server(State) ->
        receive
            update ->
                NewState = ?MODULE:upgrade(State),
                ?MODULE:server(NewState);  %% loop in the new version of the module
            SomeMessage ->
                %% do something here
                server(State)  %% stay in the same version no matter what.
        end.

    upgrade(OldState) ->
        %% transform and return the state here.
  #+END_SRC
* Namespaces
- Erlang has a flat module structure
- You can test for any clashes with the function =code:clash/0=.
* OTP
  a naive demonstration of core OTP

  kitty_server
  #+BEGIN_SRC erlang
    -module(kitty_server).
    -compile(export_all).
    -record(cat, {name,color=green, description}).

    %% ################################################################
    %% CLIENT API
    start_link() ->
        my_server:start_link(?MODULE, []).

    %% Synchronous call
    order_cat(Pid, Name, Color, Description) ->
        my_server:call(Pid, {order, Name, Color, Description}).

    %% Synchronous call
    close_shop(Pid) ->
        my_server:call(Pid, terminate).

    %% Asynchronous
    return_cat(Pid, Cat = #cat{}) ->
        my_server:cast(Pid, {return, Cat}).

    %% ################################################################
    %% called by server

    init(InitialState) ->
        InitialState.

    handle_call({order, Name, Color, Description}, From, []) ->
        my_server:reply(From, make_cat(Name, Color, Description)),
        [];

    handle_call({order, _Name, _Color, _Description}, From, Cats) ->
        my_server:reply(From, {hd(Cats)}),
        tl(Cats);

    handle_call(terminate, From, Cats) ->
        my_server:reply(From, ok),
        terminate(Cats).

    handle_cast({return, Cat}, Cats) ->
        [Cat | Cats].

    %% ################################################################
    %% private helpers
    make_cat(Name, Col, Desc) ->
        #cat{name=Name, color=Col, description=Desc}.

    terminate(Cats) ->
        [io:format("~p was set free.~n", [C#cat.name]) || C <- Cats],
        exit(normal).
  #+END_SRC

  my_server
  #+BEGIN_SRC erlang
    -module(my_server).
    -compile(export_all).

    %% Public API
    start(Module, InitialState) ->
        spawn(fun() -> init(Module, InitialState) end).

    start_link(Module, InitialState) ->
        spawn_link(fun() -> init(Module, InitialState) end).

    call(LoopPid, Msg) ->
        Ref = erlang:monitor(process, LoopPid),
        LoopPid ! {sync, self(), Ref, Msg},
        receive
            {Ref, Reply} ->
                erlang:demonitor(Ref, [flush]),
                Reply;
            {'DOWN', Ref, process, LoopPid, Reason} ->
                erlang:error(Reason)
        after 5000 ->
                erlang:error(timeout)
        end.

    cast(LoopPid, Msg) ->
        LoopPid ! {async, Msg},
        ok.

    reply({ClientPid, Ref}, Reply) ->
        ClientPid ! {Ref, Reply}.

    %% Private
    loop(Module, State) ->
        receive
            {async, Msg} ->
                loop(Module, Module:handle_cast(Msg, State));
            {sync, ClientPid, Ref, Msg} ->
                loop(Module, Module:handle_call(Msg, {ClientPid, Ref}, State))
        end.

    init(Module, InitialState) ->
        loop(Module, Module:init(InitialState)).
  #+END_SRC

  1. To fire up the server: We call kitty's =start_link=
     =kitty_server:start_link= -> =my_server:start_link= -> =my_server:init= -> =kitty_server:init=
     and we get the Pid of our server(that is the Pid of the loop in my_server).
  2. Let's order a cat by calling =order_cat=
     =kitty_server:order_cat= ->
     =my_server:call=, (sends a messeage the the loop and waits for a message) ~>
     =my_server:loop= ->
     =kitty_server:handle_call=, (sends a message to =my_server:call= which is waiting) ~>
     =my_server:call=

* =gen_server=
| gen_server     | YourModule    |
|----------------+---------------|
| start/3-4      | init/1        |
| start_link/3-4 | init/1        |
| call/2-3       | handle_call/3 |
| cast/2         | handle_cast/2 |

And then you have the other callbacks, those that are more about
special cases:
 + =handle_info/2=
 + =terminate/2=
 + =code_change/3=

** =init/1=
- used to initialize the server's state and do all of these one-time
  tasks that it will depend on
- The function can return:
  ={ok, State}=, ={ok, State, TimeOut}=, ={ok, State, hibernate}=, ={stop, Reason}= or =ignore=.
- =TimeOut=: a deadline before which you expect the server to receive
  a message. If no message is received before the deadline, the atom
  =timeout= is sent to the server, which should be handled with
  =handle_info/2=
- =hibernate=:
- On the other hand, if you do expect the process to take a long time
  before getting a reply and are worried about memory, you can add the
  =hibernate= atom to the tuple. Hibernation basically reduces the size
  of the process' state until it gets a message, at the cost of some
  processing power. If you are in doubt about using hibernation, you
  probably don't need it. Search for =erlang:hibernate=
- ={stop, Reason}=, should be done when something went wrong during
  the initialization.

- While =init/1= is running, execution is blocked in the process that
  spawned the server. This is because it is waiting for a '=ready='
  message sent automatically by the =gen_server= module to make sure
  everything went fine.
** =handle_call/3=
- is used to work with synchronous messages
- There are 8 different return values possible, taking the form of
  tuples:
  1. ={reply, Reply, NewState}=
  2. ={reply, Reply, NewState, Timeout}=
  3. ={reply, Reply, NewState, hibernate}=

  4. ={noreply, NewState}=
  5. ={noreply, NewState, Timeout}=
  6. ={noreply, NewState, hibernate}=

  7. ={stop, Reason, Reply, NewState}=
  8. ={stop, Reason, NewState}=

- When you use =noreply=, the generic part of the server will assume
  you're taking care of sending the reply back yourself. This can be
  done with =gen_server:reply/2=
** =handle_cast/2=
- is used to handle asynchronous calls
- return values
  1. ={noreply, NewState}=
  2. ={noreply, NewState, Timeout}=
  3. ={noreply, NewState, hibernate}=
  4. ={stop, Reason, NewState}=

** =handle_info/2=
- it returns the same tuples as =handle_cast=
- But the difference is that this callback is only there for messages that
  were sent directly with the =!= operator and special ones like
  =init/1='s =timeout=, monitors' notifications and '=EXIT=' signals.
** =terminate/2=
- is called whenever one of the three =handle_Something= functions
  returns a tuple of the form ={stop, Reason, NewState}= or ={stop, Reason, Reply, NewState}=.
  It takes two parameters, =Reason= and =State=,
- will also be called when its parent (the process that spawned it)
  dies, if and only if the =gen_server= is trapping exits
- return value of this function doesn't really matter

** =code_change/3=
- is there to let you upgrade code
- takes the form =code_change(PreviousVersion, State, Extra)=
- the variable =PreviousVersion= is either the version term itself in
  the case of an upgrade (=myModule:module_info=), or ={down,
  Version}= in the case of a downgrade (just reloading older
  code). The =State= variable holds all of the current's server state so
  you can convert it.

* behaviour
- A behaviour is basically a way for a module to specify functions it
  expects another module to have. The behaviour is the contract
  sealing the deal between the well-behaved generic part of the code
  and the specific, error-prone part of the code
- For defining your own behaviours you need to export a function
  called =behaviour_info/1= implemented as follows:
  #+BEGIN_SRC erlang
    -module(my_behaviour).
    -export([behaviour_info/1]).

    %% init/1, some_fun/0 and other/3 are now expected callbacks
    behaviour_info(callbacks) -> [{init,1}, {some_fun, 0}, {other, 3}];
    behaviour_info(_) -> undefined.
  #+END_SRC
  use it like =-behaviour(my_behaviour)=.

* Generic Finite-State Machines, =gen_fsm=
- Somewhat similar to =gen_server= in that it is a specialised version
  of it. The biggest difference is that rather than handling calls and
  casts, we're handling synchronous and asynchronous events.

|-----------------------------------+----------------------------|
| *gen_fsm module*                  | *Callback module*          |
|-----------------------------------+----------------------------|
| gen_fsm:start_link                | Module:init/1              |
|-----------------------------------+----------------------------|
| gen_fsm:send_event                | Module:StateName/2         |
|-----------------------------------+----------------------------|
| gen_fsm:send_all_state_event      | Module:handle_event/3      |
|-----------------------------------+----------------------------|
| gen_fsm:sync_send_event           | Module:StateName/3         |
|-----------------------------------+----------------------------|
| gen_fsm:sync_send_all_state_event | Module:handle_sync_event/4 |
|-----------------------------------+----------------------------|
| -                                 | Module:handle_info/3       |
| -                                 | Module:terminate/3         |
| -                                 | Module:code_change/4       |

** =Module:init/1=
- the return values accepted are:
  + ={ok, StateName, Data}=
  + ={ok, StateName, Data, Timeout}=
  + ={ok, StateName, Data, hibernate}=
  + ={stop, Reason}=

- =StateName= is an atom and represents the next callback function to be called

** =Module:StateName/2-3=
- The functions =StateName/2= and =StateName/3= are placeholder names
  and you are to decide what they will be.

- suppose the =init/1= function returns the tuple ={ok, sitting, dog}=.
  This means the finite state machine will be in a =sitting=
  state. This is not the same kind of state as we had seen with
  =gen_server=; These states dictate a context in which you handle a
  given event. Now whenever the =gen_fsm= process receives an event, either
  the function =sitting/2= or =sitting/3= will be called. The =sitting/2=
  function is called for *asynchronous* events and =sitting/3= for
  *synchronous* ones.

- *=StateName(Event, StateData)=*
  + is called for *asynchronous* events
  + Asynchronous events aimed at any =StateName/2= function are sent
    with =gen_fsm:send_event/2=
  + =Event= is the actual message sent as an event, and
    =StateData= is the data that was carried over the calls
  + can return:
    * ={next_state, NextStateName, NewStateData}=
    * ={next_state, NextStateName, NewStateData, Timeout}=
    * ={next_state, NextStateName, NewStateData, hibernate}=
    * ={stop, Reason, NewStateData}=

- *=StateName(Event, From, StateData)=*
  + is called for *synchronous* events
  + synchronous events to be picked up by =StateName/3= are to be sent
    with =gen_fsm:sync_send_event/2-3=
  + can return:
    * ={reply, Reply, NextStateName, NewStateData}=
    * ={reply, Reply, NextStateName, NewStateData, Timeout}=
    * ={reply, Reply, NextStateName, NewStateData, hibernate}=

    * ={next_state, NextStateName, NewStateData}=
    * ={next_state, NextStateName, NewStateData, Timeout}=
    * ={next_state, NextStateName, NewStateData, hibernate}=

    * ={stop, Reason, Reply, NewStateData}=
    * ={stop, Reason, NewStateData}=

** =Module:handle_event(Event, StateName, Data)=
- is used for asynchronous global events that would trigger a specific
  reaction no matter what state we're in
- =StateName= in parameters shows what the state was when the =Event=
  was received
- returns the same values as =StateName/2=.
- =Event= is sent by =gen_fsm:send_all_state_event=

** =Module:handle_sync_event(Event, From, StateName, Data)=
- It handles synchronous global events, and returns the same kind of
  tuples as =StateName/3=.
- =Event= is sent by =gen_fsm:sync_send_all_state_event=
** =Module:code_change/4=
- like =gen_servers= except that it takes an extra state parameter
  when called like =code_change(OldVersion, StateName, Data, Extra)=,
  and returns a tuple of the form ={ok, NextStateName, NewStateData}=.
** =Module:terminate/3=
- like generic servers, =terminate/3= should do the opposite of =init/1=

** =gen_fsm:send_event(FsmRef, Event)=
- Asynchronous events aimed at any =StateName/2= function
- its equivalent function for global events is =send_all_state_event/2=

** =gen_fsm:sync_send_event(FsmRef, Event, [Timeout])=
- Synchronous events to be picked up by =StateName/3= are to be sent
  with =sync_send_event/2-3=.
- its equivalent function for global events is  =sync_send_all_state_event/2-3=
** =gen_fsm:send_all_state_event(FsmRef, Event)=
- for sending global asynchronous events, picked up by
  =handle_event(Event, StateName, Data)=
** =gen_fsm:sync_send_all_state_event(FsmRef, Event, [Timeout])=
- for sending global synchronous events, picked up b
  =handle_sync_event(Event, From, StateName, Data)=
** =gen_fsm:reply(Caller, Reply)=
* Generic Event Handlers =gen_event=
:NOTE:
    - Remember that event handlers run in the same process as their manager.
:END:

This behavior module provides event handling functionality. It
consists of a generic event manager process with any number of event
handlers that are added and deleted dynamically.

| =gen_event= module           | Callback module         |
|------------------------------+-------------------------|
| =gen_event:start=            |                         |
| =gen_event:start_link=       | -                       |
|                              |                         |
| =gen_event:add_handler=      |                         |
| =gen_event:add_sup_handler=  | =Module:init/1=         |
|                              |                         |
| =gen_event:notify=           |                         |
| =gen_event:sync_notify=      | =Module:handle_event/2= |
|                              |                         |
| =gen_event:call=             | =Module:handle_call/2=  |
|                              |                         |
| -                            | =Module:handle_info/2=  |
|                              |                         |
| =gen_event:delete_handler=   | =Module:terminate/2=    |
|                              |                         |
| =gen_event:swap_handler=     |                         |
| =gen_event:swap_sup_handler= | =Module1:terminate/2=   |
|                              | =Module2:init/1=        |
|                              |                         |
| =gen_event:which_handlers=   | -                       |
|                              |                         |
| =gen_event:stop=             | =Module:terminate/2=    |
|                              |                         |
| -                            | =Module:code_change/3=  |

** =Module:init/1= and =Module:terminate/2=
- =init/1= takes a list of arguments and returns ={ok, State}=.
- Whatever happens in =init/1= should have its counterpart in =terminate/2=.
** =Module:handle_event(Event, State)=
- it works asynchronously, it means event manager doesn't block the
  calling process for the event handler to fnish (don't get confused
  by this. It does block event manager [event manager queues new
  events] and other event handlers have to to get their event. If you
  have more than one event handler, they are all running in one
  process and that is process of event man anger)
- can return:
  + ={ok, NewState}=
  + ={ok, NewState, hibernate}=, which puts the event manager itself into hibernation until the next event
  + =remove_handler=
  + ={ swap_handler, Args1, NewState, NewHandler, Args2}=

- All incoming events can come from =gen_event:notify/2= which is
  asynchronous like =gen_server:cast/2= is. There is also
  =gen_event:sync_notify/2= which is synchronous. This is a bit funny to
  say, because =handle_event/2= remains asynchronous. The idea here is
  that the function call only returns once all event handlers have
  seen and treated the new message. Until then, the event manager will
  keep blocking the calling process by not replying.
** =Module:handle_call(Event, State)=
- This is similar to a =gen_server='s =handle_call= callback
- can return
  + ={ok, Reply, NewState}=
  + ={ok, Reply, NewState, hibernate}=
  + ={remove_handler, Reply}=
  + ={swap_handler, Reply, Args1, NewState, Handler2, Args2}=
- The =gen_event:call/3-4= function is used to make the call
  + =gen_event:call(EventMgrRef, Handler, Request)=

** =Module:handle_info(Event, State)=
   The =handle_info/2= callback is pretty much the same as =handle_event=
   (same return values and everything), with the exception that it
   only treats out of band messages, such as exit signals, messages
   sent directly to the event manager with the ! operator, etc.
** =Module:code_change(OldVsn, State, Extra)=
** example of callback module
   #+BEGIN_SRC erlang
     -module(mymodule).
     -behaviour(gen_event).

     -export([init/1, handle_event/2, handle_call/2, handle_info/2, code_change/3, terminate/2]).

     init([]) ->
     {ok, []}.

     handle_event(_, State) ->
     {ok, State}.

     handle_call(_, State) ->
     {ok, ok, State}.

     handle_info(_, State) ->
     {ok, State}.

     code_change(_OldVsn, State, _Extra) ->
     {ok, State}.

     terminate(_Reason, _State) ->
     ok.
   #+END_SRC
** =gen_event:start_link()=
** =gen_event:add_handler(EventMgrRef, Handler, Args)=
- Also possible =gen_event:add_handler(Pid, {Module, Ref}, Args)=
  which is usefull If you want to call, add or delete a specific
  handler when there's more than one instance of it.
** =gen_event:add_sup_handler(EventMgrRef, Handler, Args)=
- Adds a new event handler in the same way as =add_handler/3=, but also
  supervises the connection between the event handler and the calling
  process.
** =gen_event:notify(EventMgrRef, Event)=
** =gen_event:sync_notify(EventMgrRef, Event)=
** =gen_event:delete_handler(EventMgrRef, Handler, Args)=
- The event manager calls =Module:terminate/2= to terminate the event
  handler.
- The return value is the return value of =Module:terminate/2=.
** =gen_event:call(EventMgrRef, Handler, Request)=
- Makes a synchronous call to event handler =Handler= installed in event
  manager =EventMgrRef= by sending a request and waiting until a reply
  arrives or a time-out occurs. The event manager calls
  =Module:handle_call/2= to handle the request.
* supervisor
- workers should never be used in any position except under another
  supervisor
- - When we start our supervisor by calling =supervisor:start_link(Module, Args)= or
  =supervisor:start_link(SupName, Module, Args)=, =init/1= function of =Module= is called
** =Module:init/1=
- should return
  ={ok, {{RestartStrategy, MaxRestart, MaxTime},[ChildSpecs]}}=.
- RestartStrategy can be any of =one_for_one=, =rest_for_one=, =one_for_all= and =simple_one_for_one=.
  + =one_for_one=: if your supervisor supervises many workers and one of
    them fails, only that one should be restarted.
  + =one_for_all=: whenever all your processes under a single supervisor
    heavily depend on each other to be able to work normally.
    + =rest_for_one=: Whenever you have to start processes that depend on
     each other in a chain (A starts B, which starts C, which starts D,
     etc.), you can use =rest_for_one=. It's also useful in the case of
     services where you have similar dependencies (X works alone, but Y
     depends on X and Z depends on both). What a =rest_for_one= restarting
     strategy does, basically, is make it so if a process dies, all the
     ones that were started after it (depend on it) get restarted, but
     not the other way around.
  + =simple_one_for_one=:
    * explained [[*=simple_one_for_one=][here]]


- Restart limits: if more than =MaxRestarts= (all the children
  combined) happen within =MaxTime= (in seconds), the supervisor just
  gives up on your code, shuts it down then kills itself to never
  return.

** Child Specifications
- is like ={ChildId, StartFunc, Restart, Shutdown, Type, Modules}=

#+BEGIN_SRC erlang
  [{
    fake_id,                                      %% ChildId
    {fake_mod, start_link, [SomeArg]},            %% StartFunc
    permanent,                                    %% Restart
    5000,                                         %% Shutdown
    worker,                                       %% Type
    [fake_mod]                                    %% Modules
   },
   {other_id,
    {event_manager_mod, start_link, []},
    transient,
    infinity,
    worker,
    dynamic}]
#+END_SRC

*** ChildId
The =ChildId= is just an internal name used by the supervisor
internally. You will rarely need to use it yourself, although it might
be useful for debugging purposes and sometimes when you decide to
actually get a list of all the children of a supervisor. Any term can
be used for the Id.
*** StartFunc
=StartFunc= is a tuple that tells how to start the child. It's the
standard ={M,F,A}= format we've used a few times already. Note that it
is very important that the starting function here is OTP-compliant and
links to its caller when executed (hint: use =gen_*:start_link()=
wrapped in your own module, all the time).

*** Restart
Restart tells the supervisor how to react when that particular child
dies. This can take three values:
1. =permanent=: should always be restarted, no matter what.
2. =temporary=: a process that should never be restarted
3. =transient=: They're meant to run until they terminate normally and
   then they won't be restarted. However, if they die of abnormal
   causes (exit reason is anything but =normal=), they're going to be
   restarted. This restart option is often used for workers that need
   to succeed at their task, but won't be used after they do so.

You can have children of all three kinds mixed under a single
supervisor. This might affect the restart strategy: a =one_for_all=
restart won't be triggered by a temporary process dying, but that
temporary process might be restarted under the same supervisor if a
permanent process dies first!

*** Shutdown
The Shutdown value of a child specification is us used to give a
deadline on the termination. On certain workers, you know you might
have to do things like properly close files, notify a service that
you're leaving, etc. In these cases, you might want to use a certain
cutoff time, either in milliseconds or infinity if you are really
patient. If the time passes and nothing happens, the process is then
brutally killed with =exit(Pid, kill)=. If you don't care about the
child and it can pretty much die without any consequences without any
timeout needed, the atom =brutal_kill= is also an acceptable
value. =brutal_kill= will make it so the child is killed with
=exit(Pid, kill)=, which is untrappable and instantaneous.
*** Type
Type simply lets the supervisor know whether the child is a worker or
a supervisor.

*** Modules

** Dynamic Supervision
- in normal supervisors (none =simple_one_for_one=) we have have the
  following facilities but because the internal representation is a
  list, this won't work very well when you need quick access to many
  children. For that we use =simple_one_for_one= strategy
  + =start_child(SupervisorNameOrPid, ChildSpec)=
    * This adds a child specification to the list and starts the child
      with it
  + =terminate_child(SupervisorNameOrPid, ChildId)=
    * Terminates or =brutal_kills= the child. The child specification is
      left in the supervisor
  + =restart_child(SupervisorNameOrPid, ChildId)=
    * Uses the child specification to get things rolling.
  + =delete_child(SupervisorNameOrPid, ChildId)=
    * Gets rid of the ChildSpec of the specified child
  + =check_childspecs([ChildSpec])=
    * Makes sure a child specification is valid. You can use this to try
      it before using =start_child/2=.
  + =count_children(SupervisorNameOrPid)=
    * Counts all the children under the supervisor and gives you a
      little comparative list of who's active, how many specs there are,
      how many are supervisors and how many are workers.
  + =which_children(SupervisorNameOrPid)=
    * gives you a list of all the children under the supervisor.

*** =simple_one_for_one=
- makes it so it takes only one kind of children, and
  it's to be used when you want to dynamically add them to the
  supervisor, rather than having them started statically
- a =simple_one_for_one= supervisor just sits around there, and it
  knows it can produce one kind of child only. Whenever you want a
  new one, you ask for it and you get it.
- =one_for_one= holds a *list* of all the children it has (and
  had, if you don't clear it), started in order, while
  =simple_one_for_one= holds a single definition for all its
  children and works using a *dict* to hold its data. Basically,
  when a process crashes, the =simple_one_for_one= supervisor will
  be much faster when you have a large number of children.
- Note: it is important to note that =simple_one_for_one= children
  are not respecting this rule with the *Shutdown* time. In the case
  of =simple_one_for_one=, the supervisor will just exit and it will
  be left to each of the workers to terminate on their own, after
  their supervisor is gone.
- The problem with =simple_one_for_one= is that it will not allow you
  to manually restart a child, delete it or terminate it.
- All the children are held in a dictionary (hence fast lookup)
- There is a single child specification for all children
- For the most part, writing a =simple_one_for_one= supervisor is
  similar to writing any other type of supervisor, except for one
  thing. The argument list in the ={M,F,A}= tuple is not the whole
  thing, but is going to be appended to what you call it with when you
  do =supervisor:start_child(Sup, Args)=. That's right,
  =supervisor:start_child/2= changes API. So instead of doing
  =supervisor:start_child(Sup, Spec)=, which would call
  =erlang:apply(M,F,A)=, we now have =supervisor:start_child(Sup, Args)=,
  which calls =erlang:apply(M,F,A++Args)=.
- to terminate a child =supervisor:terminate_child(SupRef, Id)=
* how to cope with the loss of state
Supervisors kill processes, state is lost, how to handle it?

- different kinds of state:
  + *Static state*: This type can easily be fetched from a config file,
    another process or the supervisor restarting the application.
  + *Dynamic state*: /composed of data you can re-compute./ This
    includes state that you had to transform from its initial form to
    get where it is right now
  + *Dynamic data*: /you can not recompute./ This might include user
    input, live data, sequences of external events, etc.

- The idea of an onion layered system is to allow all of these
  different states to be protected correctly by isolating different
  kinds of code from each other. It's process segregation.
- the most important data (or the hardest to find back) has to be the
  most protected type. The places where you are actually not allowed
  to fail is called the error kernel of your application. The error
  kernel is likely the place where you'll want to use try...catches
  more than anywhere else, where handling exceptional cases is vital.
- all kinds of operations related together should be part of the same
  supervision trees, and the unrelated ones should be kept in
  different trees. Within the same tree, operations that are
  failure-prone but not vital can be in a separate sub-tree.
* OTP application
#+BEGIN_SRC shell
  ebin/           # compiled files
  include/        # Erlang header (.hrl) files
  priv/           # executables, other programs, and various specific files needed for the application to work
  src/            # Erlang source files
  test/
#+END_SRC
** The Application Resource File
- This file will tell the Erlang VM what the application is, where it
  begins and where it ends. This file lives on in the =ebin/= directory,
  along with all the compiled modules.
- This file is usually named =<yourapp>.app=
- The basic structure of the application file is simply: ={application, ApplicationName, Properties}=.
- =ApplicationName= is an atom
- =Properties= is a list of ={Key, Value}= tuples describing the application.
  + ={description, "Some description of your application"}= The field
    is optional and defaults to an empty string.
  + ={vsn, "1.2.3"}= to help with upgrades and downgrades, the string
    is used to identify your application's version.
  + ={modules, ModuleList}=
    Contains a list of all the modules that your application
    introduces to the system. A module always belongs to at most one
    application and can not be present in two applications' app files
    at once. This list lets the system and tools look at dependencies
    of your application, making sure everything is where it needs to
    be and that you have no conflicts with other applications already
    loaded in the system. If you're using a standard OTP structure and
    are using a build tool like =rebar3=, this is handled for you.
  + ={registered, AtomList}= Contains a list of all the names
    registered by the application. This lets OTP know when there will
    be name clashes when you try to bundle a bunch of applications
    together, but is entirely based on trusting the developers to give
    good data. We all know this isn't always the case, so blind faith
    shouldn't be used in this case.
  + ={env, [{Key, Val}]}= This is a list of key/values that can be
    used as a configuration for your application. They can be obtained
    at run time by calling =application:get_env(Key)= or
    =application:get_env(AppName, Key)=. The first one will try to find
    the value in the application file of whatever application you are
    in at the moment of the call, the second allows you to specify an
    application in particular. This stuff can be overwritten as
    required (either at boot time or by using =application:set_env/3-4=.
  + ={maxT, Milliseconds}= This is the maximum time that the
    application can run, after which it will be shut down. This is a
    rather rarely used item and Milliseconds defaults to infinity, so
    you often don't need to bother with this one at all.
  + ={applications, AtomList}= A list of applications on which yours
    depends. The application system of Erlang will make sure they were
    loaded and/or started before allowing yours to do so. All
    applications depend at least on =kernel= and =stdlib=.
    :NOTE:
    Even though all applications depend on the =kernel= and the
    =stdlib= applications, We don't have to mention them and everything
    works because starting the Erlang VM starts these applications
    automatically. You might feel like adding them for the sake of
    expliciteness, but there's no need for it right now.
    :END:
  + ={mod, {CallbackMod, Args}}= Defines a callback module for the
    application, using the application behaviour. This tells OTP that
    when starting your application, it should call
    =CallbackMod:start(normal, Args)=. This function's return value will
    be used when OTP will call =CallbackMod:stop(StartReturn)= when
    stopping your application. People will tend to name =CallbackMod=
    after their application.
** The Application Behaviour
- Remember that behaviours are always about splitting generic code
  away from specific code.
- They denote the idea that your specific code gives up its own
  execution flow and inserts itself as a bunch of callbacks to be used
  by the generic code.
- In the case of applications, this generic part is quite complex and
  not nearly as simple as other behaviours.
- Whenever the VM first starts up, a process called the application
  controller is started (with the name =application_controller=). It
  starts all other applications and sits on top of most of them (well,
  not all of them, check out the following NOTE). In fact, you could
  say the application controller acts a bit like a supervisor for all
  applications.
  :Note:
  - the Application Controller technically doesn't sit over all the
    applications. One exception is the kernel application, which
    itself starts a process named user. The user process in fact acts
    as a group leader to the application controller and the kernel
    application thus needs some special treatment.

  - In Erlang, the IO system depends on a concept called a group
    leader. The group leader represents standard input and output and
    is inherited by all processes. There is a hidden IO protocol that
    the group leader and any process calling IO functions communicate
    with. The group leader then takes the responsibility of forwarding
    these messages to whatever input/output channels there are

  - The main task of the group leader is to collect the I/O output
    from all the processes in its group and pass that I/O to or from
    the underlying system. Basically the group leader owns stdin,
    stdout, and stderr on behalf of the group and handles passing
    information to and from channels like those. [[https://stackoverflow.com/questions/36318766/what-is-a-group-leader#comment60274161_36319970][SO comment]]

  - Think about the group leader as a proxy, through which other
    processes do their IO. So, instead of a group of developers all
    talking to the accounting department, they appoint a group leader
    who talks for them and they can continue hacking their code. [[https://stackoverflow.com/questions/36318766/what-is-a-group-leader#comment60279093_36319970][So Comment]]

  :END:
- when someone decides they want to start an application, the
  application controller (AC) starts an
  application master. The application master is in fact two processes
  taking charge of each individual application: they set it up and act
  like a middleman in between your application's top supervisor and
  the application controller.
 #+BEGIN_SRC
                                     |------------------------|
                ---------------------| Application Controller |------------------------
                |                    |------------------------|                       |
                |                                |                                    |
                |                                |                                    |
    |------------------------|      |------------------------|             |------------------------|
    |   Application Master   |      |    Application Master  |             |    Application Master  |
    |------------------------|      |------------------------|             |------------------------|
                |                                |                                    |
                |                                |                                    |
    |------------------------|      |------------------------|             |------------------------|
    |       supervisor       |      |      supervisor        |             |      supervisor        |
    |------------------------|      |------------------------|             |------------------------|
                |                                |                                    |
                |                                |                                    |
                .                                .                                    .
                .                                .                                    .
 #+END_SRC

- the application callback module requires: =start/2= and =stop/1=.
- =start/2=: =YourMod:start(Type, Args)=,
  + the =Type= will always be =normal= (the other possibilities
    accepted have to do with distributed applications)
  + =Args= is what is coming from your app file.
  + needs to return the Pid of the application's top-level supervisor
    in one of the two following forms: ={ok, Pid}= or ={ok, Pid, SomeState}=.
    If you don't return SomeState, it simply defaults to =[]=.
- =stop/1=: takes the state returned by =start/2= as an argument.
- we can start the app by =application:start(foobar).=
  This tells the application controller to launch our =foobar=
  application.
- list running applications =application:which_applications()=
- to stop an application =application:stop(foobar).=
- we can give different arguments to =application:start=.
  + Application started with: =application:start(AppName, temporary)=
    * When ends normally: Nothing special happens, the application has stopped.
    * When Ends abnormally: The error is reported, and the application terminates without restarting.
  + Application started with: =application:start(AppName, transient)=
    * When ends normally: Nothing special happens, the application has stopped.
    * When ends abnormally: The error is reported, all the other applications are stopped and the VM shuts down.
  + Application started with: =application:start(AppName, permanent)=
    * When ends normally: All other applications are terminated and the VM shuts down.
    * When ends abnormally: Same; all applications are terminated, the VM shuts down.
*** Library Applications
- What happens when we want to wrap flat modules in an application but
  we have no process to start and thus no need for an application
  callback module? the only thing is to remove the tuple
  ={mod, {Module, Args}}= from the application file. This is
  called a library application.
* Included Applications
- It is more and more recommended *not* to use included applications for
  a simple reason: they seriously limit code reuse.
- eleases can basically help us do the same (and much more) in a more
  generic manner.
* Complex Terminations
- There are cases where we need more steps to be done before
  terminating our application. The =stop/1= function from the
  application callback module might not be enough, especially since it
  gets called after the application has already terminated. What do we
  do if we need to clean things up before the application is actually
  gone?
- The trick is simple. Just add a function =prep_stop(State)= to your
  application callback module. State will be the state returned by
  your =start/2= function, and whatever =prep_stop/1= returns will be
  passed to =stop/1=. The function =prep_stop/1= thus technically inserts
  itself between =start/2= and =stop/1= and is executed while your
  application is still alive, but just before it shuts down.
* OTP releases
- =init:stop()=
  + All applications are taken down smoothly, all code is unloaded,
    and all ports are closed before the system terminates by calling
    =halt(Status)=. If command-line flag =-heart= was specified, the heart
    program is terminated before the Erlang node terminates.

** Releases With =systools=
- The =systools= application is the simplest one to build Erlang releases.

- =rel= file example
  + We can get the =erts= (Erlang Run Time System) by oppening =erl=
  + We can get the =stdlib= and =kernel= versions by =application:which_applications()=
  #+BEGIN_SRC erlang
    {release,
     {"erlcount", "1.0.0"},
     {erts, "10.2"},
     [{kernel, "6.2"},
      {stdlib, "3.7"},
      {ppool, "1.0.0", permanent},
      {erlcount, "1.0.0", transient}]}.
  #+END_SRC
  + we named the release =erlcount= and =made= it version =1.0.0=.

***  boot file
- Erlang's virtual machine can start itself with a basic configuration
  taken from something called a boot file. In fact, when you start
  your own erl application from the shell, it implicitly calls the
  Erlang Run Time System with a default boot file. That boot file will
  give basic instructions such as 'load the standard library', 'load
  the kernel application', 'run a given function' and so on. That boot
  file is a binary file created from something called a boot script,
  which contains tuples that will represent these instructions.
*** boot script
- The boot script is something easy to generate from the =.rel= file.
  1. open =erl= where there's your =.rel= file, =erl -env ERL_LIBS .=
  2. generate the boot script and boot file via =systools:make_script("erlcount-1.0", [local]).=
- the =local= option means that we want the release to be possible to run from anywhere,
- created an archive file: =systools:make_tar("erlcount-1.0", [{erts, "/usr/lib/erlang/"}]).=
  + systools will look for your release files and the Erlang Run Time
    System (because of the erts option). If you omit the erts option,
    the release won't be self-executable and will depend on the
    presence of Erlang already being installed on a system
  + to run it after extracting the archive
    =$ ./erts-10.2/bin/erl -b releases/1.0.0/start=

** Releases With =reltool=
- [[http://erlang.org/doc/man/reltool.html][Fucking doc]]
- [[Https://learnyousomeerlang.com/release-is-the-word][LYSE chapter]]
- Reltool works from a config file that looks like this:
  #+BEGIN_SRC erlang
    {sys, [
           {lib_dirs, ["/home/farhad/play/release/"]},
           {rel, "erlcount", "1.0.0",
            [kernel,
             stdlib,
             {ppool, permanent},
             {erlcount, transient}
            ]},
           {boot_rel, "erlcount"},
           {relocatable, true},
           {profile, standalone},
           {app, ppool, [{vsn, "1.0.0"},
                         {app_file, all},
                         {debug_info, keep}]},
           {app, erlcount, [{vsn, "1.0.0"},
                            {incl_cond, include},
                            {app_file, strip},
                            {debug_info, strip}]}
          ]}.
  #+END_SRC
- =Reltool= will take different levels of information. The first
 level will contain release-wide information. The second level will
 be application-specific, and the third is control at a
 module-specific level
  + Release level: environment, applications of the releases,
    properties of the releases
  + Applications level: what to include, compression, debug-info, app files, etc.
  + Modules level: what to include, debug-info
- Some of the useful options
  + =lib_dirs=: The option is =lib_dirs= and it takes a list of
    directories where applications are sitting. So really, instead of
    adding =-env ERL_LIBS <list of directories>=, you put in ={lib_dirs, [ListOfDirectories]}=
    #+BEGIN_SRC erlang
    {lib_dirs, ["/home/farhad/play/release/"]},
    #+END_SRC
  + =rel=: very similar to the =.rel= file for =systools=, that's what
    we need to specify what apps need to be started correctly.
    #+BEGIN_SRC erlang
      {rel, "erlcount", "1.0.0",
       [kernel,
        stdlib,
        {ppool, permanent},
        {erlcount, transient}
       ]},
    #+END_SRC
  + =boot_rel=:
    #+BEGIN_SRC erlang
    {boot_rel, "erlcount"}
    #+END_SRC
    This will tell Reltool that whenever someone runs the =erl= binary
    included in the release, we want the apps from the =erlcount=
    release to be started
- With just these 3 options (=lib_dirs=, =rel= and =boot_rel=), we can get a valid release.

  =/home/farhad/play/release/erlcount-1.0.config=:
  #+BEGIN_SRC erlang
  {sys, [
       {lib_dirs, ["/home/farhad/play/release/"]},
       {rel, "erlcount", "1.0.0",
        [kernel,1
         stdlib,
         {ppool, permanent},
         {erlcount, transient}
        ]},
       {boot_rel, "erlcount"}
      ]}.
  #+END_SRC
  NOTE: create =rel= directory which is passed to =reltool:eval_target_spec= first =mkdir rel=
  #+BEGIN_SRC shell
    1> {ok, Conf} = file:consult("erlcount-1.0.config").
    {ok,[{sys,[{lib_dirs,["/home/farhad/play/release/"]},
    {rel,"erlcount","1.0.0",
    [kernel,stdlib,{ppool,permanent},{erlcount,transient}]},
    {boot_rel,"erlcount"}]}]}

    2> {ok, Spec} = reltool:get_target_spec(Conf).
    {ok,[{create_dir,"releases",
    ...

    3> reltool:eval_target_spec(Spec, code:root_dir(), "rel").
    ok
  #+END_SRC
  to run it
  #+BEGIN_SRC
  $ cd rel
  $ ./bin/erl -noshell
    Regex if\s.+-> has 0 results
    Regex case\s.+\sof has 0 results
  #+END_SRC
- to handle version with =reltool=
  + If you have older versions of Erlang installed, you can add an
    ={erts, [{vsn, Version}]}= like ={erts, [{vsn, "5.8.3"}]}= entry
    to the config file:
*** reltool config file options
More thorough explanation of options in reltool config file
**** Release-only options
- ={lib_dirs, [ListOfDirs]}=
  + What directories to look inside for libraries.
- ={app, AppName, [AppOptions]}=
  + Will let you specify application-wide options, usually more
    specific than the release-wide options.
- ={boot_rel, ReleaseName}=
  + Default release to boot with the erl executable. This means we
    won't need to specify the boot file when calling erl.
- ={rel, Name, Vsn, [Apps]}=
  + The applications to be included in the release.
- ={profile, development | embedded | standalone}=
  + This option will act as a way to specify default =*_filters=
    based on your type of release. By default,
    development is used. That one will include more files from each
    app and ERTS blindly. The standalone profile will be more
    restrictive, and the embedded profile even more so, dropping more
    default ERTS applications and binaries.
**** Release and Application-wide Options
Note that for all of these, setting the option on the level of an
application will simply override the value you gave at a system level.
- ={incl_sys_filters, [RegularExpressions]}= and ={excl_sys_filters, [RegularExpressions]}=
  + Checks whether a file matches the include filters without matching
    the exclude filters before including it. You might drop or include
    specific files that way.

- ={incl_app_filters, [RegularExpressions]}= and ={excl_app_filters, [RegularExpressions]}=
  + Similar to =incl_sys_filters= and =excl_sys_filters=, but for application-specific files

- ={incl_archive_filters, [RegularExpressions]}= and
  ={excl_archive_filters, [RegularExpressions]}=
  + Specified what top-level directories have to be included or
    excluded into .ez archive files.

- ={incl_cond, include | exclude | derived}=
  + Decides how to include applications not necessarily specified in
    the =rel= tuple. Picking include means that Reltool will include
    pretty much everything it can find. Picking derived means that
    Reltool will only include applications that it detects can be used
    by any of the applications in your rel tuple. This is the default
    value. Picking exclude will mean that you will include no apps at
    all by default. You usually set this on a release-level when you
    want minimal includes, and then override it on an
    application-by-application basis for the stuff you feel like
    adding.
- ={mod_cond, all | app | ebin | derived | none}=
  + This controls the module inclusion policy. Picking none means no
    modules will be kept. That's not very useful. The derived option
    means that Reltool will try to figure out what modules are used by
    other modules which are already included and add them in that
    case. Setting the option to app will mean that Reltool keeps all
    the modules mentioned in the app file and those that were
    derived. Setting it to ebin will keep those in the ebin/ directory
    and the derived ones. Using the option all will be a mix of using
    ebin and app. That's the default value.
- ={app_file, keep | strip | all}=
  + This option manages how the app files are going to be managed for
    you when you include an application. Picking keep will guarantee
    that the app file used in the release is the same one you wrote
    for your application. That's the default option. If you choose
    strip, Reltool will try to generate a new app file that removes
    the modules you don't want in there (those that were excluded by
    filters and other options). Choosing all will keep the original
    file, but will also add specifically included modules in
    there. The nice thing with all is that it can generate app files
    for you if none are available.
**** Module-specific Options
- ={incl_cond, include | exclude | derived}=
  + This lets you override the mod_cond option defined at the release
    level and application level.
**** All-levels Options
These options work on all levels. The lower the level, the more
precedence it takes.
- ={debug_info, keep | strip}=
 + Assuming your files were compiled with debug_info on (which I
   suggest you do), this option lets you decide whether to keep it or
   drop it. The =debug_info= is useful when you want to decompile files,
   debug them, etc. but will take some space
**** Recipes
***** Development versions
- basic would suffice for development
  #+BEGIN_SRC erlang
    {sys, [
           {lib_dirs, ["/home/farhad/play/release/"]},
           {rel, "erlcount", "1.0.0", [kernel, stdlib, ppool, erlcount]},
           {boot_rel, "erlcount"}
          ]}.
  #+END_SRC
- you might want to have everything from a regular VM
  #+BEGIN_SRC erlang
  {sys, [
           {lib_dirs, ["/home/farhad/play/release/"]},
           {rel, "start_clean", "1.0.0", [kernel, stdlib]},
           {incl_cond, include},
           {debug_info, keep}
          ]}.
  #+END_SRC
  By setting =incl_cond= to =include=, all applications found in the
  current ERTS install and the lib_dirs will be part of your release.
- we want to exclude a specific application, =foo=
  #+BEGIN_SRC erlang
    {sys, [
           {lib_dirs, ["/home/farhad/play/release/"]},
           {rel, "start_clean", "1.0.0", [kernel, stdlib]},
           {incl_cond, include},
           {debug_info, keep},
           {app, foo, [{incl_cond, exclude}]}
          ]}.
  #+END_SRC
  Here we can specify one or more applications (each having its own
  =app= tuple), and each of them overrides the =incl_cond= setting put at
  the release level. So in this case, we will include everything
  except =foo=.

***** Only importing or exporting part of a library
- to exclude, let's say test files, because we don't need them in our
  release
  #+BEGIN_SRC erlang
    {sys, [
           {lib_dirs, ["/home/farhad/play/release/"]},
           {rel, "start_clean", "1.0.0", [kernel, stdlib, ppool, erlcount]},
           {excl_app_filters, ["_tests.beam$"]}
          ]}.
  #+END_SRC
- when you want to only import specific files of an application, let's
  say our =erlcount_lib=
  #+BEGIN_SRC erlang
    {sys, [
           {lib_dirs, ["/home/farhad/play/release/"]},
           {rel, "start_clean", "1.0.0", [kernel, stdlib]},
           {incl_cond, derived}, % exclude would also work, but not include
           {app, erlcount, [{incl_app_filters, ["^ebin/erlcount_lib.beam$"]},
                            {incl_cond, include}]}
          ]}.
  #+END_SRC
  In this case, we switched from ={incl_cond, include}= to more
  restrictive =incl_cond=s. This is because if you go large and rake
  everything is, then the only way to include a single lib is to
  exclude all the others with an =excl_app_filters=. However, when our
  selection is more restrictive (in this case we're =derived= and
  wouldn't include =erlcount= because it's not part of the =rel= tuple),
  we can specifically tell the release to include the =erlcount= app
  with only files that match the regular expression having to do with
  =erlcount_lib=.
* Live code upgrade
- if you're changing the interface your modules give to the
  world: changing internal data structures, changing function names,
  modifying records (remember, they're tuples!), etc. They all have
  the potential to crash things.
- you can suspend OTP processes by calling =sys:suspend(PidOrName)= (you
  can find all of the processes using the supervision trees and
  looking at the children each supervisor has). Then you use
  =sys:change_code(PidOrName, Mod, OldVsn, Extra)= to force the process
  to update itself, and finally, you call =sys:resume(PidOrName)= to
  make things go again.
- =appups=: files containing instructions on how to update individual applications
- =relups= file containing instructions to update an entire release
- SASL (System Architecture Support Libraries) is mandatory to be able
  to do =appups= on a system. If you forget to include SASL in your
  release, it will be impossible to upgrade the system
- Without =debug_info=, doing an =appup= will fail
** Appup Files
- =appup= file must be named =NameOfYourApp.appup= and be put in the
  app's =ebin/= directory.
- Appup files are lists of Erlang commands that need to be done to
  upgrade a given application. They contain lists of tuples and atoms
  telling what to do and in what case. The general format for them is:
  #+BEGIN_SRC erlang
  {NewVersion,
     [{VersionUpgradingFrom, [Instructions]}]
     [{VersionDownGradingTo, [Instructions]}]}.
  #+END_SRC
- The instructions contain both high-level and low-level commands. We
  usually only need to care about high-level ones, though.
  + ={add_module, Mod}=
    The module =Mod= is loaded for the first time.
  + ={load_module, Mod}=
    The module =Mod= is already loaded in the VM and has been modified.
  + ={delete_module, Mod}=
    The module =Mod= is removed from the VM.
  + ={update, Mod, {advanced, Extra}}= This will suspend all processes
    running =Mod=, call the code_change function of your module with
    Extra as the last argument, then resume all processes running
    =Mod=. Extra can be used to pass in arbitrary data to the
    code_change function, in case it's required for upgrades.
  + ={update, Mod, supervisor}= Calling this lets you re-define the
    init function of a supervisor to influence its restart strategy
    (one_for_one, rest_for_one, etc.) or change child specifications
    (this will not affect existing processes).
  + ={apply, {M, F, A}}=
      Will call =apply(M,F,A)=.
  + *Module dependencies*: You can use ={load_module, Mod, [ModDependencies]}= or
    ={update, Mod, {advanced, Extra}, [ModDeps]}=
    to make sure that a command happens only after some other modules
    were handled beforehand. This is especially useful if =Mod= and its
    dependencies are not part of the same application. There is sadly
    no way to give similar dependencies to delete_module instructions.
  + *Adding or removing an application*: When generating relups, we won't
    need any special instructions to remove or add applications. The
    function that generates =relup= files (files to upgrade releases)
    will take care of detecting this for us.

** a recipe for a functional relups:
1. Write OTP applications for your first software iteration
2. Compile them
3. Build a release (1.0.0) using Reltool. It must have debug info and no =.ez= archive.
4. Make sure you create the RELEASES file at some point before
   starting your production application. You can do it with
   =release_handler:create_RELEASES(RootDir, ReleasesDir, Relfile,
   [{AppName, Vsn, LibDir}]).=
5. Run the release!
6. Find bugs in it
7. Fix bugs in new versions of applications
8. Write =appup= files for each of the applications
9. Compile the new applications
10. Build a new release (1.1.0 in our case). It must have debug info and no =.ez= archive
11. Copy =rel/releases/NewVsn/RelName.rel= as =rel/releases/NewVsn/RelName-NewVsn.rel=
12. Copy =rel/releases/NewVsn/RelName.boot= as =rel/releases/NewVsn/RelName-NewVsn.boot=
13. Copy =rel/releases/NewVsn/RelName.boot= as =rel/releases/NewVsn/start.boot=
14. Copy =rel/releases/OldVsn/RelName.rel= as =rel/releases/OldVsn/RelName-OldVsn.rel=
15. Copy =rel/releases/OldVsn/RelName.boot= as =rel/releases/OldVsn/RelName-OldVsn.boot=
16. Copy =rel/releases/OldVsn/RelName.boot= as =rel/releases/OldVsn/start.boot=
17. Generate a relup file with
    #+BEGIN_SRC erlang
    =systools:make_relup("rel/releases/Vsn/RelName-Vsn",
                         ["rel/releases/OldVsn/RelName-OldVsn"],
                         ["rel/releases/DownVsn/RelName-DownVsn"]).=
    #+END_SRC
18. Move the relup file to =rel/releases/Vsn=
19. Generate a tar file of the new release with =systools:make_tar("rel/releases/Vsn/RelName-Vsn").=
20. Move the tar file to =rel/releases/=
21. Have some shell opened that still runs the first version of the release
22. Call =release_handler:unpack_release("NameOfRel-Vsn").=
23. Call =release_handler:install_release(Vsn).=
24. Call =release_handler:make_permanent(Vsn).=
25. Make sure things went fine. If not, rollback by installing an older version.

* IO Lists
- for text, we can use either strings (lists of integers) or
  binaries (a binary data structure holding data).
- IO lists are a type of data structure. They are lists of
  either bytes (integers from 0 to 255), binaries, or other IO
  lists. This means that functions that accept IO lists can accept
  items such as =[$H, $e, [$l, <<"lo">>, " "], [[["W","o"], <<"rl">>]] | [<<"d">>]]=.
  When this happens, the Erlang VM will just flatten the list as it needs to do it
  to obtain the sequence of characters =Hello World=
- What are the functions that accept such IO Lists? Most of the
  functions that have to do with outputting data do. Any function from
  the =io= module, =file= module, TCP and UDP sockets will be able to
  handle them. Some library functions, such as some coming from the
  =unicode= module and all of the functions from the =re= (for regular
  expressions) module will also handle them, to name a few.
  #+BEGIN_SRC
    erl> IoList = [$H, $e, [$l, <<"lo">>, " "], [[["W","o"], <<"rl">>]] | [<<"d">>]].

    erl> io:format("~s~n", [IoList]).
    Hello World
  #+END_SRC
* UDP
- opening a socket can be done by =gen_udp:open/1-2=
  #+BEGIN_SRC erlang
      {ok, Socket} = gen_udp:open(PortNumber).
  #+END_SRC
  + The second argument can be a list of options, specifying in what
    type we want to receive data (=list= or =binary=), how we want them
    received; as messages (={active, true}=) or as results of a function
    call (={active, false}=). There are more options such as whether the
    socket should be set with IPv4 (=inet4=) or IPv6 (=inet6=), whether
    the UDP socket can be used to broadcast information (={broadcast,
    true | false}=), the size of buffers, etc.

- send and receive messages
  #+BEGIN_SRC erlang

  1> {ok, Socket} = gen_udp:open(8790).
    {ok,#Port<0.587>}

  % gen_udp:send(OwnSocket, RemoteAddress, RemotePort, Message)
  2> gen_udp:send(Socket, {127,0,0,1}, 8789, "hey there!").
    ok
  #+END_SRC
  The =RemoteAddress= can be either a string or an
  atom containing a domain name ("example.org"), a 4-tuple describing
  an IPv4 address or a 8-tuple describing an IPv6 address. Then we
  specify the receiver's port number, and then the message, which can be a
  string, a binary, or an IO list.
  on the other side we get ={udp,#Port<0.6>,{127,0,0,1},8790,<<"hey there!">>}= that
  is ={udp, Socket, FromIp, FromPort, Message}=
  + receiving in passive mode (={active, false}=)
    #+BEGIN_SRC erlang
      erl> {ok, Socket} = gen_udp:open(8789, [binary, {active,false}]).
       {ok,#Port<0.683>}

      erl> gen_udp:recv(Socket, 0). % makes the shell stuck until it receives a msg
    #+END_SRC
    The function here is =recv/2=. This is the function used to poll a
    passive socket for messages. The =0= here is the length of the
    message we want. The funny thing is that the length is completely
    ignored with =gen_udp=. =gen_tcp= has a similar function, and in
    that case, it does have an impact. Anyway, if we never send a
    message, =recv/2= is never going to return. There's also a
    =recv/3= that you can specify how long do you want to wait.

- close the socket
  #+BEGIN_SRC erlang
  gen_udp:close(Socket).
  #+END_SRC
* TCP
- There's two kind of TCP socket, TCP client sockets and TCP accept sockets
- start a /listen socket/ with =gen_tcp:listen(Port, Options)=:
  #+BEGIN_SRC erlang
  erl> {ok, ListenSocket} = gen_tcp:listen(8091, [{active,true}, binary]).

  {ok,#Port<0.661>}
  #+END_SRC
  + The listen socket is just in charge of waiting for connection requests.
  + TCP and UDP mostly have similar options. But the TCP ones do have
    a few more specific options, including a connection backlog
    (={backlog, N}=), keepalive sockets (={keepalive, true | false}=),
    packet packaging (={packet, N}=, where =N= is the length of each
    packet's header to be stripped and parsed for you), etc.
- Once the listen socket is open, any process (and more than one) can
  take the listen socket and fall into an 'accepting' state, locked up
  until some client asks to talk with it:
  #+BEGIN_SRC erlang
    %% in shell 1
    5> {ok, ListenSocket} = gen_tcp:listen(8091, [{active, true}, binary]).
    {ok,#Port<0.728>}

    6> {ok, AcceptSocket} = gen_tcp:accept(ListenSocket). % locked up until some client asks to talk with it
  #+END_SRC
  to connect to it from another shell
  #+BEGIN_SRC erlang
  %% in shell 2
    erl> {ok, Socket} = gen_tcp:connect({127,0,0,1}, 8091, [binary, {active,true}]).
    {ok,#Port<0.8>}
  #+END_SRC
  then we can send a msg
  #+BEGIN_SRC erlang
  %% in shell 2
  erl> gen_tcp:send(Socket, "Hey there first shell!").
  ok
  #+END_SRC
  we've received the message in shell one
  #+BEGIN_SRC erlang
    %% in shell 1
    erl> flush().
     Shell got {tcp,#Port<0.729>,<<"Hey there first shell!">>}
     ok
  #+END_SRC
- Both sockets can send messages in the same way, and can then be
  closed with =gen_tcp:close(Socket)=. Note that closing an accept
  socket will close that socket alone, and closing a listen socket
  will close none of the related and established accept sockets, but
  will interrupt currently running accept calls by returning ={error, closed}=.

** socket ownership
- UDP sockets, TCP client sockets and TCP accept sockets can all have
  messages sent through them from any process in existence, but
  messages received can only be read by the process that started the
  socket.
- Both =gen_tcp= and =gen_udp= contain a function called
  =controlling_process(Socket, Pid)=. This function has to be called by
  the current socket owner. Then the process tells Erlang 'you know
  what? Just let this =Pid= guy take over my socket. I give up'. From
  now on, the =Pid= in the function is the one that can read and receive
  messages from the socket.
* inet
- =inet= takes care of handling all operations that can be common to
  both =gen_tcp= and =gen_udp= sockets. For changing between active
  and passive modes, there's a function named =inet:setopts(Socket, Options)=.
  The option list can contain any terms used at the setup
  of a socket.

- example
  #+BEGIN_SRC erlang
    1> {ok, Listen} = gen_tcp:listen(8088, [{active, false}]).
    {ok,#Port<0.6>}

    2> {ok, Accept} = gen_tcp:accept(Listen).
    {ok,#Port<0.7>}

    %%
    %% from another shell we sent a msg
    %% {ok, Socket} = gen_tcp:connect({127,0,0,1}, 8088, []), gen_tcp:send(Socket, "hey there").
    %%
    4> flush().
    ok                                              %% oops, we weren't in active mode, let's fix it

    6> inet:setopts(Accept, [{active, true}]).
    ok

    7> flush().
    Shell got {tcp,#Port<0.7>,"hey there"}
    ok
  #+END_SRC
- active once:
  #+BEGIN_SRC erlang
    %% shell 1
    inet:setopts(Accept, [{active, once}]).
  #+END_SRC
  from another shell we send two messages
  #+BEGIN_SRC erlang
    %% shell 2
    erl> gen_tcp:send(Socket, "one").
      ok
    erl> gen_tcp:send(Socket, "two").
      ok
  #+END_SRC
  and we receive one of the message each time
  #+BEGIN_SRC erlang
    %% shell 1
    erl> flush().
    Shell got {tcp,#Port<0.598>,"one"}
    ok

    erl> flush().
    ok

    erl> inet:setopts(Accept, [{active, once}]).
    ok

    erl> flush().
    Shell got {tcp,#Port<0.598>,"two"}
    ok
  #+END_SRC
  Until we ask for ={active, once}= a second time, the message ="two"=
  hasn't been converted to a message, which means the socket was back
  to passive mode. So the active once mode allows us to do that
  back-and-forth switch between active and passive in a safe way. Nice
  semantics, plus the safety.

- Starting with version 17.0, it is now possible to tell a port to be
  active for N packets. The ={active, N}= option for TCP and UDP ports
  has been added, where N can be any value from 0 to 32767. Once the
  remaining message counter either reaches 0 or is explicitly set to 0
  through =inet:setopts/2=, the socket transitions to passive (={active, false}=) mode.
  At that point, a message is sent to the socket's
  controlling process to inform it of the transition. The message will
  be ={tcp_passive, Socket}=, and ={udp_passive, Socket}= for UDP.
* EUnit
- ~?assert(Expression)~, ~?assertNot(Expression)~
  + Will test for boolean values. If any value other than true makes
    it into ~?assert~, an error will be shown. Same for ~?assertNot~, but
    for negative values. This macro is somewhat equivalent to ~true = X~
    or ~false = Y~.
- ~?assertEqual(A, B)~
  + Does a strict comparison (equivalent to ~=:=~) between two
    expressions, ~A~ and ~B~. If they are different, a failure will
    occur. This is roughly equivalent to ~true = X =:= Y~.
    ~?assertNotEqual~ is available to do the opposite of
    ~?assertEqual~.
- ~?assertMatch(Pattern, Expression)~
  + This allows us to match in a form similar to ~Pattern = Expression~,
    without variables ever binding. This means that I could do
    something like ~?assertMatch({X,X}, some_function())~ and assert
    that I receive a tuple with two elements being
    identical. Moreover, I could later do ~?assertMatch(X,Y)~ and ~X~
    would not be bound.  This is to say that rather than properly
    being like ~Pattern = Expression~, what we have is closer to:
    #+BEGIN_SRC erlang
        (fun (Pattern) -> true; (_) -> erlang:error(nomatch) end)(Expression)
    #+END_SRC
    variables in the pattern's head never get bound across multiple
    assertions. The macro ~?assertNotMatch~ is also available.
- ~?assertError(Pattern, Expression)~
  + Tells EUnit that Expression should result in an error. As an
    example, ~?assertError(badarith, 1/0)~ would be a successful test

- ~?assertThrow(Pattern, Expression)~
  + Exactly the same as ~?assertError~, but with ~throw(Pattern)~
    instead of ~erlang:error(Pattern)~.
- ~?assertExit(Pattern, Expression)~
  + Exactly the same as ~?assertError~, but with ~exit(Pattern)~ (and
    not ~exit/2~) instead of ~erlang:error(Pattern)~.

-  ~?assertException(Class, Pattern, Expression)~
  + A general form of the three previous macros. As an example,
    ~?assertException(error, Pattern, Expression)~ is the same as
    ~?assertError(Pattern, Expression)~. ~?assertNotException/3~ is
    also available.
** Test Generators
- Test generators are pretty much shorthand for assertions wrapped in
  functions that can be run later, in clever manners.
- Instead of having functions ending with ~_test()~ with macros that are
  of the form ~?assertSomething~, we will use functions that end in
  ~_test_()~ and macros of the form ~?_assertSomething~
  #+BEGIN_SRC erlang
    function_test() -> ?assert(A == B).             %% regular
    function_test_() -> ?_assert(A == B).           %% generator
  #+END_SRC
  example
  #+BEGIN_SRC erlang
    %% only add_test_() ends in _test_()

    add_test_() ->
        [test_them_types(),
         test_them_values(),
         ?_assertError(badarith, 1/0)].

    test_them_types() ->
        ?_assert(is_number(ops:add(1,2))).

    test_them_values() ->
        [?_assertEqual(4, ops:add(2,2)),
         ?_assertEqual(3, ops:add(1,2)),
         ?_assertEqual(3, ops:add(1,1))].
  #+END_SRC

** test representation
   example
   #+BEGIN_SRC
   eunit:test({generator, fun ops_tests:add_test_/0}).
   #+END_SRC
   + ~{module, Mod}~: runs all tests in ~Mod~
   + ~{dir, Path}~: runs all the tests for the modules found in ~Path~
   + ~{file, Path}~: runs all the tests found in a single compiled module
   + ~{generator, Fun}~: runs a single generator function as a test
   + ~{application, AppName}~: runs all the tests for all the modules
     mentioned in ~AppName's~ ~.app~ file.
** Fixtures
- allows you to build a general structure that allows us to define
  setup and teardown functions for each of the test. These functions
  will allow you to build the state and environment required for each
  of the tests to be useful. Moreover, the scaffolding will let you
  specify how to run the tests (do you want to run them locally, in
  separate processes, etc.?)
*** setup fixture
- A setup fixture takes one of the many following forms:
  #+BEGIN_SRC erlang
  {setup, Setup, Instantiator}
  {setup, Setup, Cleanup, Instantiator}
  {setup, Where, Setup, Instantiator}
  {setup, Where, Setup, Cleanup, Instantiator}
  #+END_SRC
  example:
  #+BEGIN_SRC erlang
    double_register_test_() ->
        {setup,
         fun start/0,               % setup function
         fun stop/1,                % teardown function
         fun two_names_one_pid/1}.  % instantiator

    start() ->
        {ok, Pid} = registry:start_link(),
        Pid.

    stop(Pid) ->
        registry:stop(Pid).

    two_names_one_pid(Pid) ->
        ok = registry:register(Pid, quite_a_unique_name, self()),
        Res = registry:register(Pid, my_other_name_is_more_creative, self()),
        [?_assertEqual({error, already_named}, Res)].
  #+END_SRC
  the whole fixture can be put inside a test:
  #+BEGIN_SRC erlang
    some_test_() ->
        [{setup, fun start/0, fun stop/1, fun some_instantiator1/1},
         {setup, fun start/0, fun stop/1, fun some_instantiator2/1},
         ...
         {setup, fun start/0, fun stop/1, fun some_instantiatorN/1}].
  #+END_SRC

- Setup
  + A function that takes no argument. Each of the tests will be
    passed the value returned by the setup function.
- Cleanup
  + A function that takes the result of a setup function as an
    argument, and takes care of cleaning up whatever is needed. If in
    OTP ~terminate~ does the opposite of ~init~, then cleanup functions
    are the opposite of setup functions for EUnit.
- Instantiator
  + It's a function that takes the result of a setup function and
    returns a test set (remember, test sets are possibly deeply nested
    lists of ~?_Macro~ assertions).
- Where
  + Specifies how to run the tests: ~local~, ~spawn~, ~{spawn, node()}~.

*** foreach fixture
#+BEGIN_SRC erlang
    {foreach, Where, Setup, Cleanup, [Instantiator]}
    {foreach, Setup, Cleanup, [Instantiator]}
    {foreach, Where, Setup, [Instantiator]}
    {foreach, Setup, [Instantiator]}
#+END_SRC
- it's like the setup fixture with the difference that it takes lists
  of instantiators.
  #+BEGIN_SRC erlang
    some2_test_() ->
        {foreach,
         fun start/0,
         fun stop/1,
         [fun some_instantiator1/1,
          fun some_instantiator2/1,
          ...
          fun some_instantiatorN/1]}.
  #+END_SRC

- what if you want to run ~start/0~ and ~stop/1~ once for all the tests?
  #+BEGIN_SRC erlang
    some_tricky_test_() ->
        {setup,
         fun start/0,
         fun stop/1,
         fun (SetupData) ->
                 [some_instantiator1(SetupData),
                  some_instantiator2(SetupData),
                  ...
                  some_instantiatorN(SetupData)]
         end}.
  #+END_SRC
** How tests should run?
- ~{spawn, TestSet}~
  + Runs tests in a separate process than the main test process. The
    test process will wait for all of the spawned tests to finish
- ~{timeout, Seconds, TestSet}~
  + The tests will run for Seconds number of Seconds. If they take
    longer than Seconds to finish, they will be terminated without
    further ado.
- ~{inorder, TestSet}~
  + This tells EUnit to run the tests within the test set strictly in
    the order they are returned.
- ~{inparallel, Tests}~
  + Where possible, the tests will be run in parallel.
- example
  #+BEGIN_SRC erlang
    some_tricky2_test_() ->
        {setup,
         fun start/0,
         fun stop/1,
         fun(SetupData) ->
                 {inparallel,
                  [some_instantiator1(SetupData),
                   some_instantiator2(SetupData),
                   ...
                   some_instantiatorN(SetupData)]}
         end}.
  #+END_SRC
** add description to tests
   #+BEGIN_SRC erlang
     double_register_test_() ->
         {"Verifies that the registry doesn't allow a single process to "
          "be registered under two names. We assume that each pid has the "
          "exclusive right to only one name",
          {setup,
           fun start/0,
           fun stop/1,
           fun two_names_one_pid/1}}.
   #+END_SRC
** to get the guts of a process
#+BEGIN_SRC
erl> regis_server:start_link().
{ok,<0.160.0>}

erl> regis_server:register(shell, self()).
ok

erl> sys:get_status(whereis(regis_server)).
{status,<0.160.0>,
        {module,gen_server},
        [[{'$ancestors',[<0.31.0>]},
          {'$initial_call',{regis_server,init,1}}],
         running,<0.31.0>,[],
         [{header,"Status for generic server regis_server"},
          {data,[{"Status",running},
                 {"Parent",<0.31.0>},
                 {"Logged events",[]}]},
          {data,[{"State",
                  {state,{1,{<0.31.0>,{shell,#Ref<0.0.0.333>},nil,nil}},
                         {1,{shell,{<0.31.0>,#Ref<0.0.0.333>},nil,nil}}}}]}]]}
#+END_SRC
* ETS
- ETS (Erlang Term Storage) tables allow limited concurrency in reads and writes (much
  better than none at all for a process' mailbox) in a way that could
  let us optimize away a lot of the pain.
- The main design objectives ETS had was to provide a way to store
  large amounts of data in Erlang with constant access time
  (functional data structures usually tend to flirt with logarithmic
  access time) and to have such storage look as if it were implemented
  as processes in order to keep their use simple and idiomatic.
- ways to store data into tables:
  + ~set~
    * Sets are great when you need to use a standard key/value store
      with constant time access
  + ~ordered_set~
    * The first element of the table is the smallest one, and the last
      element is the largest one.
    * If you traverse a table iteratively (jumping to the next element
      over and over again), the values should be increasing, which is
      not necessarily true of set tables. Ordered set tables are great
      when you frequently need to operate on ranges (I want entries 12
      to 50 !). They will, however, have the downside of being slower
      in their access time (~O(log N)~).
    * ~ordered_set~ tables will see the values ~1~ and ~1.0~ as identical
      for all operations. Other tables will see them as different.

  + ~bag~
    * A bag table can have multiple entries with the same key, as long
      as the tuples themselves are different. This means that the
      table can have ~{key, some, values}~ and ~{key, other, values}~
      inside of it without a problem, which would be impossible with
      sets (they have the same key). However, you couldn't have ~{key, some, values}~
      twice in the table as they would be entirely identical.
  + ~duplicate_bag~
    * The tables of this type work like bag tables, with the exception
      that they do allow entirely identical tuples to be held multiple
      time within the same table.
- controlling process:
  + much like sockets, when a process calls a function that starts a
    new ETS table, that process is the owner of the table
  + By default, only the owner of the table can write to it, but
    everyone can read from it. This is known as the protected level of
    permissions. You can also choose to set the permissions to public,
    where everyone can read and write, or private, where only the
    owner can read or write.
  + The ETS table is intimately linked to the process. If the process
    dies, the table disappears (and so does all of its
    content). However, the table can be given away, much like we did
    with sockets and their controlling processes, or a heir can be
    determined so that if the owner process dies, the table is
    automatically given away to the heir process.
- ~ets:new/2~ options:
  + ~Type = set | ordered_set | bag | duplicate_bag~
    * default is ~set~
  + ~Access = private | protected | public~
    * default is ~protected~
  + ~named_table~
    * if you call ~ets:new(some_name, [])~, you'll be starting a
      ~protected~ set table, without a name. For the name to be used as
      a way to contact a table (and to be made unique), the option
      ~named_table~ has to be passed to the function. Otherwise, the
      name of the table will purely be for documentation purposes and
      will appear in functions such as ~ets:i()~, which print
      information about all ETS tables in the system.
  + ~{keypos, Position}~
    * The ~Position~ parameter holds an integer from 1 to N telling
      which of each tuple's element shall act as the primary key of
      the database table. The default key position is set to 1.
    * This means you have to be careful if you're using records as
      each record's first element is always going to be the record's
      name (remember what they look like in their tuple form). If you
      want to use any field as the key, use ~{keypos, #RecordName.FieldName}~,
      as it will return the position of ~FieldName~ within the
      record's tuple representation.
    * The tuples do not have to all be of the same size in an ETS
      table, although it should be seen as good practice to do so. It
      is however necessary that the tuple is at least of the same size
      (or greater) than whatever the key position is.
  + ~{heir, Pid, Data} | {heir, none}~
    * ETS tables have a process that acts as their parent. If the
      process dies, the table disappears.
    * If the process attached to a table dies, the heir receives a
      message saying ~{'ETS-TRANSFER', TableId, FromPid, Data}~, where
      ~Data~ is the element passed when the option was first
      defined. The table is automatically inherited by the heir.
    * By default, no heir is defined. It is possible to define or
      change a heir at a later point in time by calling
      ~ets:setopts(Table, {heir, Pid, Data})~ or ~ets:setopts(Table, {heir, none})~.
      If you simply want to give the table away, call ~ets:give_away/3~.
  + ~{read_concurrency, true | false}~
    * optimize the table for read concurrency
    * make switching to writes a lot more expensive
    * If you do some reading, some writing and they are interleaved,
      using this option might even hurt performance
  + ~{write_concurrency, true | false}~
    * Usually, writing to a table will lock the whole thing and nobody
      else can access it, either for reading or writing to it, until
      the write is done.
    * Setting this option to 'true' lets both reads and writes be done
      concurrently, without affecting the ACID properties of ETS.
    * Doing this, however, will reduce the performance of sequential
      writes by a single process and also the capacity of concurrent
      reads. You can combine this option with '~read_concurrency~' when
      both writes and reads come in large bursts.
  + ~compressed~
    * will allow the data in the table to be compressed for most
      fields, but not the primary key. This comes at the cost of
      performance when it comes to inspecting entire elements of the
      table
- ~ets:delete(Table)~
  + where Table is either a table id or the name of a named table
- ~ets:delete(Table, Key)~
  + if you want to delete a single entry from the table
- ~ets:insert(Table, ObjectOrObjects)~
  + ~ObjectOrObjects~ can be either a single tuple or a list of tuples to insert
  + inserting the same key twice overwrites it. This will always
    happen in sets and ordered sets, but not in bags or duplicate
    bags. If you want to avoid this use ~ets:insert_new/2~, as it will
    only insert elements if they are not in the table already.
- ~ets:lookup(Table, Key)~
- ~ets:tab2list/1~
- ~ets:tab2file/~
- ~ets:file2tab/1~
- ~ets:i/0~
- ~ets:info(Table)~
- ~ets:match/2~
  + returns the variables of the pattern
- ~ets:match_object/2~
  + returns the whole entry that matched the pattern
- ~ets:match_delete(Table, Pattern)~
  + delete entries based on a pattern match

- traversing tables:
  Whenever you're trying to iterate outside of a table, you'll see
  ~$end_of_table~ atoms.
  + ~ets:next~
  + ~ets:prev~
  + ~ets:fist~
  + ~ets:last~
- pattern matching in ETS
  + used with ~match/2~, ~match_object/2~, ~match/3~ and ~match_object/3~
  + ~{items, '$3', '$1', '_', '$3'}~ roughly equivalent to saying
    ~{items, C, A, _, C}~ with regular pattern matching. Numbers in
    variables have no explicit meaning, but their order is important.
  + example
    #+BEGIN_SRC erlang
      1> ets:new(table, [named_table, bag]).
      table

      2> ets:insert(table, [{items, a, b, c, d}, {items, a, b, c, a}, {cat, brown, soft, loveable, selfish}, {friends, [jenn,jeff,etc]}, {items, 1, 2, 3, 1}]).
      true

      3> ets:match(table, {items, '$1', '$2', '_', '$1'}).
      [[a,b],[1,2]]

      4> ets:match(table, {items, '$114', '$212', '_', '$6'}).
      [[d,a,b],[a,a,b],[1,1,2]]

      5> ets:match_object(table, {items, '$1', '$2', '_', '$1'}).
      [{items,a,b,c,a},{items,1,2,3,1}]

      6> ets:delete(table).
      true
    #+END_SRC
** match specifications
-
    #+BEGIN_SRC erlang
    [Clause1,
     Clause2]
    #+END_SRC
-
    #+BEGIN_SRC erlang
    [{InitialPattern1, Guards1, ReturnedValue1},
    {InitialPattern2, Guards2, ReturnedValue2}].
    #+END_SRC

-
    #+BEGIN_SRC erlang
      [
       {                                              %% first clause begin
        {'$1','$2',<<1>>,'$3','$4'},                  %% pattern
        [{'andalso',{'>','$4',150},{'<','$4',500}},   %% guard
         {'orelse',{'==','$2',meat},{'==','$2',dairy}}], %% another guard
        ['$1']                                        %% return value
       },                                             %% first clause ends
       {
        {'$1','$2',<<1>>,'$3','$4'},
        [{'<','$3',4.0},{is_float,'$3'}],
        ['$1']
       }
      ]
    #+END_SRC
- *guards*: Each operator or guard function works with a prefix syntax,
  meaning that we use the order ~{FunctionOrOperator, Arg1, ..., ArgN}~. So
  ~is_list(X)~ becomes ~{is_list, '$1'}~, ~X andalso Y~ becomes ~{'andalso', X, Y}~,
  and so on. Reserved keywords such as ~andalso~, ~orelse~ and
  operators like ~==~ need to be put into atoms so the Erlang parser
  won't choke on them.
- *return value*: If you want to return the full input of the match
  specification, use the variable ~'$_'~ to do so
** parse transform
- They let Erlang programmers transform the code in a module to a new
  alternative form. Parse transforms can be pretty much anything and
  change existing Erlang code to almost anything else, as long as it
  doesn't change the language's syntax or its tokens.
- The parse transform coming with ETS needs to be enabled manually for
  each module that needs it
  #+BEGIN_SRC erlang
    -module(SomeModule).
    -include_lib("stdlib/include/ms_transform.hrl").
    ...
    some_function() ->
    ets:fun2ms(fun(X) when X > 4 -> X end).         %% ms being match specification
  #+END_SRC
- The line ~-include_lib("stdlib/include/ms_transform.hrl").~ contains
  some special code that will override the meaning of
  ~ets:fun2ms(SomeLiteralFun)~ whenever it's being used in a
  module. Rather than being a higher order function, the parse
  transform will analyse what is in the fun (the pattern, the guards
  and the return value), remove the function call to ~ets:fun2ms/1~, and
  replace it all with an actual match specification.
  + example
    #+BEGIN_SRC erlang
      1> ets:fun2ms(fun(X) -> X end).
        [{'$1',[],['$1']}]

      2> ets:fun2ms(fun({X,Y}) -> X+Y end).
        [{{'$1','$2'},[],[{'+','$1','$2'}]}]

      3> ets:fun2ms(fun({X,Y}) when X < Y -> X+Y end).
        [{{'$1','$2'},[{'<','$1','$2'}],[{'+','$1','$2'}]}]

      4> ets:fun2ms(fun({X,Y}) when X < Y, X rem 2 == 0 -> X+Y end).
        [{{'$1','$2'},
          [{'<','$1','$2'},{'==',{'rem','$1',2},0}],
          [{'+','$1','$2'}]}]

      5> ets:fun2ms(fun({X,Y}) when X < Y, X rem 2 == 0; Y == 0 -> X end).
        [{{'$1','$2'},
          [{'<','$1','$2'},{'==',{'rem','$1',2},0}],
          ['$1']},
         {{'$1','$2'},[{'==','$2',0}],['$1']}]
    #+END_SRC

- not all funs are valid match specifications
  #+BEGIN_SRC erlang
    erl> ets:fun2ms(fun(X) -> my_own_function(X) end).
        Error: fun containing the local function call 'my_own_function/1' (called in body) cannot be translated into match_spec
        {error,transform_error}

    erl> ets:fun2ms(fun(X,Y) -> ok end).
        Error: ets:fun2ms requires fun with single variable or tuple parameter
        {error,transform_error}

    erl> ets:fun2ms(fun([X,Y]) -> ok end).
        Error: ets:fun2ms requires fun with single variable or tuple parameter
        {error,transform_error}

    erl> ets:fun2ms(fun({<<X/binary>>}) -> ok end).
        Error: fun head contains bit syntax matching of variable 'X', which cannot be translated into match_spec
        {error,transform_error}
  #+END_SRC
- using match specifications on ets
  + ~ets:select/2~
    * to fetch results,
  + ~ets:select_reverse/2~
    * to get results in reverse in ~ordered_set~ tables (for other
      types, it's the same as ~select/2~),
  + ~ets:select_count/2~
    * to know how many results match the specification
  + ~ets:select_delete/2~
    * to delete records matching a match specification.
    * Deleting has a little special twist to it. You have to return
      ~true~ in the pattern instead of any kind of value
    * example
      #+BEGIN_SRC erlang
        erl> ets:select_delete(food, ets:fun2ms(fun(#food{price=P}) when P > 5 -> true end)).
        3
      #+END_SRC
  + example:
    #+BEGIN_SRC erlang
      11> rd(food, {name, calories, price, group}).   %% define a record
      food

      12> ets:new(food, [ordered_set, {keypos,#food.name}, named_table]).
      food

      13> ets:insert(food, [#food{name=salmon, calories=88, price=4.00, group=meat},
      13>  #food{name=cereals, calories=178, price=2.79, group=bread},
      13>  #food{name=milk, calories=150, price=3.23, group=dairy},
      13>  #food{name=cake, calories=650, price=7.21, group=delicious},
      13>  #food{name=bacon, calories=800, price=6.32, group=meat},
      13>  #food{name=sandwich, calories=550, price=5.78, group=whatever}]).
      true


      14> ets:select(food, ets:fun2ms(fun(N = #food{calories=C}) when C < 600 -> N end)).
      [#food{name = cereals,calories = 178,price = 2.79,group = bread},
      #food{name = milk,calories = 150,price = 3.23,group = dairy},
      #food{name = salmon,calories = 88,price = 4.0,group = meat},
      #food{name = sandwich,calories = 550,price = 5.78,group = whatever}]


      15> ets:select_reverse(food, ets:fun2ms(fun(N = #food{calories=C}) when C < 600 -> N end)).
      [#food{name = sandwich,calories = 550,price = 5.78,group = whatever},
      #food{name = salmon,calories = 88,price = 4.0,group = meat},
      #food{name = milk,calories = 150,price = 3.23,group = dairy},
      #food{name = cereals,calories = 178,price = 2.79,group = bread}]


      16> ets:select(food, ets:fun2ms(fun(N = #food{group=delicious}) -> N end)).
      [#food{name = cake,calories = 650,price = 7.21,group = delicious}]
    #+END_SRC
* DETS
- DETS is a disk-based version of ETS, with a few key differences.
  + There are no longer ~ordered_set~ tables, there is a disk-size limit
    of 2GB for DETS files, and operations such as ~prev/1~ and ~next/1~
    are not nearly as safe or fast.
- A new database table is created by calling ~dets:open_file/2~, and is
  closed by doing ~dets:close/1~. The table can later be re-opened by
  calling ~dets:open_file/1~.
* distributed programming
- in Erlang, each VM is a node
- When you start a node, you give it a name and it will connect to an
  application called ~EPMD~ (Erlang Port Mapper Daemon), which will run
  on each of the computers which are part of your Erlang cluster. EPMD
  will act as a name server that lets nodes register themselves,
  contact other nodes, and warn you about name clashes if there are
  any.
- From this point on, a node can decide to set up a connection to
  another one. When it does so, both nodes automatically start
  monitoring each other, and they can know if the connection is
  dropped, or if a node disappears. More importantly, when a new node
  joins another node which is already part of a group of nodes
  connected together, the new node gets connected to the entire group.
** False assumptions made distributed computing
1) The Network is Reliable
   + You shouldn't assume the network is reliable. Erlang doesn't have
     any special measure for that except detecting that something went
     wrong for you.
2) There is no Latency
3) Bandwidth is Infinite
   + If two nodes are connected together, all their
     communications will tend to happen over a single TCP
     connection. That's because we generally want to maintain message
     ordering between two processes (even across the network), messages
     will be sent sequentially over the connection. That means that if
     you have one very large message, you might be blocking the channel
     for all the other messages.
   + also heartbeats are sent over the same channel as regular messages
   + too many large messages keeping heartbeats at bay for too long and
     either of the nodes will eventually assume the other is
     unresponsive and disconnect from each other.
4) The Network is Secure
   + The network isn't secure, and Erlang doesn't have anything to
     offer by default for this.
5) Topology Doesn't Change
   + The topology of your network will constantly change. If your
     application works with any of these topological details
     hard-coded, then it won't easily handle these kinds of changes in
     the network.
6) There is Only One Administrator
7) Transport Cost is Zero
   + Both in terms of time (serializing and deserializing data) and
     money (the cost of bandwidth)
8) The Network is Homogeneous
   + thinking that all components of a networked application will
     speak the same language, or will use the same formats to operate
     together.
   + we have things like [[http://www.erlang.org/doc/tutorial/cnode.html][C-nodes]]. C-nodes (or nodes in other
    languages than C) are built on the idea that any language and
    application can implement Erlang's protocol and then pretend it
    is an Erlang node in a cluster.
   + Another solution for data exchange is to use something called
     BERT or [[http://bert-rpc.org/][BERT-RPC]]. This is an exchange format like XML or JSON,
     but specified as something similar to the [[http://www.erlang.org/doc/apps/erts/erl_ext_dist.html][Erlang External Term Format]].
** CAP Theorem
- A shared-data system can have at most two of the three following properties:
  + Consistency
    * once an operation is complete it will be visible to all.
    * the idea of consistency is that all operations look as if they
      were completed as a single indivisible block even across many
      nodes
  + Availability
    * if you ask the system for some piece of data, you're able to get
      a response back. If you don't get an answer back, the system
      isn't available to you
    * in the CAP theorem the availability is only a concern to
      nodes that are not dead. A dead node cannot send responses
      because it can't receive queries in the first place. This isn't
      the same as a node that can't send a reply because a thing it
      depends on is no longer there! If the node can't take requests,
      change data or return erroneous results, it isn't technically a
      threat to the balance of the system in terms of correctness. The
      rest of the cluster just has to handle more load until it comes
      back up and can be synchronized.
  + tolerance to network Partitions
    * when a network is partitioned, all messages sent from nodes in
      one component of the partition to nodes in another component are
      lost.
- CA
  + partitions /can't/ or /won't/ happen!
  + You can't have CA. Network failure happens.
- CP
  + it should seem like there is one node
  + the CP approach is usually all about stopping modifications to the
    data so it remains consistent
- AP
  + Every request received by a non-failing node in the system must
    result in a response.

- AP to CP is a spectrum
  #+BEGIN_SRC
  Availability <--AP----------------------------------------CP--> Consistency
  #+END_SRC
- in summary only two combinations of the CAP theorem is possible: AP or
  CP. A system torn apart by a netsplit can either remain available or
  consistent, but not both.
** PACELC (read pass-elk)
If there is a Partition
    How does the system trade-off *A*vailability & *C*onsistency
Else
    How does the system trade-off *L*atency & *C*onsistency


Horizontal line is for when there is a partition
Vertical line when there's no partition
#+BEGIN_SRC
                              Consistency
                                   |
                                   |
                                   |
                                   |
                                   |
                                   |
Availability <--AP-----------------|-----------------------CP--> Consistency
                                   |
                                   |
                                   |
                                   |
                                   |
                                   |
                                 Latency
#+END_SRC
** conflict resolution
   + Last Write Wins is a conflict resolution method where whatever
     the last update was is the one to be kept. This one can be tricky
     because in distributed settings, timestamps can be off or things
     can happen at exactly the same time.
   + A winner can be picked randomly.
   + More sophisticated methods to help reduce conflicts include
     time-based methods such as last write wins, but with relative
     clocks. Relative clocks do not work with absolute time values,
     but with incrementing values every time someone modifies a
     file. If you want to know more about this, read up on Lamport
     clocks or vector clocks.
   + The onus of picking what to do with the conflict can be pushed
     back to the application (or in our case, to the survivors). The
     receiving end will just have to choose which of the conflicting
     entries is the right one. This is a bit what happens when you
     have merge conflicts with source control with SVN, Mercurial,
     Git, etc.
** Setting up an Erlang Cluster
- Erlang gives names to each of the nodes to be able to locate and
  contact them. The names are of the form ~Name@Host~, where the host is
  based on available DNS entries. All names need to be unique to avoid conflicts.
- names
  + Short Name
    * Long names are based on fully qualified domain names (~aaa.bbb.ccc~)
  + Long Name
    * based on host names without a period, and are resolved going
      through your host file or through any possible DNS entry
  + nodes with short names cannot communicate with nodes that have
    long names, and the opposite is also true.
- To pick between long and short names, you can start the Erlang VM
  with two different options: ~erl -sname short_name@domain~ or
  ~erl -name long_name@some.domain~. Note that you can also start nodes with
  only the names: ~erl -sname short_name~ or ~erl -name long_name~. Erlang
  will automatically attribute a host name based on your operating
  system's configuration. Lastly, you also have the option of starting
  a node with a name such as ~erl -name name@127.0.0.1~ to give a direct
  IP.
- to connect nodes
  #+BEGIN_SRC
  (ketchup@farhad)1> net_kernel:connect_node(fries@farhad).
  true
  #+END_SRC
- your own node name by calling the BIF ~node()~ and see who
  you're connecting to by calling the BIF ~nodes()~:
- send a msg to ~{RegisteredName, NodeName}~
  #+BEGIN_SRC erlang
    (ketchup@farhad)5> {shell, fries@farhad} ! {hello, from, self()}.
    {hello,from,<0.52.0>}

    %% other node
    (fries@farhad)2> receive {hello, from, OtherShell} -> OtherShell ! <<"hey there!">> end.
    <<"hey there!">>

    %% other node
    (ketchup@ferdmbp)6> flush().
    Shell got <<"hey there!">>
    ok
  #+END_SRC
- ~erlang:monitor_node(NodeName, Bool)~. This function will let the
  process that calls it with true as a value for ~Bool~ receive a
  message of the format ~{nodedown, NodeName}~ if the node dies.
- Unless you're writing a special library that relies on checking the
  life of other nodes, you will rarely need to use
  ~erlang:monitor_node/2~. The reason for this is that functions like
  ~link/1~ and ~monitor/2~ still work across nodes.
  #+BEGIN_SRC erlang
    (fries@farhad)> process_flag(trap_exit, true).
    false

    (fries@farhad)> link(OtherShell).
    true

    (fries@farhad)> erlang:monitor(process, OtherShell).
    #Ref<0.1153803198.241172483.31434>

    %% OtherShell dies
    (fries@farhad)> flush().
    Shell got {'EXIT',<8203.84.0>,noproc}
    Shell got {'DOWN',#Ref<0.1153803198.241172483.31434>,process,<8203.84.0>, noproc}
    ok
  #+END_SRC
- Pid of remote nodes
  #+BEGIN_SRC erlang
    (fries@farhad-pc)> OtherShell.
    <8203.84.0>
  #+END_SRC
  + what we see as a pid is just some kind of visual
    representation of what a process identifier is really like
  + The first number represents the node (where 0 means the process is
    coming from the current node), the second one is a counter, and
    the third one is a second counter for when you have so many
    processes created that the first counter is not enough.
- ~erlang:disconnect_node(Node)~: to get rid of the node without
  shutting it down.
- spawn functions on remote nodes via ~spawn/2~, ~spawn/4~, ~spawn_link/2~ and ~spawn_link/4~.
  #+BEGIN_SRC erlang
    (ketchup@farhad)> spawn(fries@farhad, fun() -> io:format("I'm on ~p~n", [node()]) end).
    I'm on fries@farhad
    <6448.50.0>
  #+END_SRC
*** Cookies
- Cookie is a little unique value that must be shared between nodes to
  allow them to connect together.
- Cookies are a mechanism used to divide clusters of nodes
- use ~-setcookie~ like ~erl -sname myawesomenode -setcookie 'awesomecookie'~
- to get cookie use ~erlang:get_cookie()~
- ~erlang:set_cookie/2~ to change the cookie. If you call
  ~erlang:set_cookie(OtherNode, Cookie)~, you will use that cookie only
  when connecting to that other node. If you instead use
  ~erlang:set_cookie(node(), Cookie)~, you'll be changing the node's
  current cookie for all future connections.
** Remote Shells
#+BEGIN_SRC
(one@farhad)1>
User switch command
--> r two@farhad
--> j
1  {shell,start,[init]}
2* {two@farhad,shell,start,[]}
--> c
Eshell V10.2  (abort with ^G)
(two@farhad)1> node().
two@farhad
#+END_SRC
- By using ~^G~ again, you can go back to your original node. Be careful
  when you stop your session though. If you call ~q()~ or ~init:stop()~,
  you'll be *terminating* the remote node!
** Hidden Nodes
- any interaction between nodes will get them to set up a
  connection. Calling ~spawn/2~ or sending a message to a foreign Pid
  are going to automatically set up connections.
- ~erlang:send(Dest, Message, [noconnect])~ function sends a
  message without creating a connection, but this is rather error
  prone.
- to connect to a node inside a cluster without connecting to all the
  nodes in that cluster we can use ~-hidden~ flag
  #+BEGIN_SRC erlang
    ▶ erl -sname three -hidden
    Erlang/OTP 21 [erts-10.2] [source] [64-bit] [smp:4:4] [ds:4:4:10] [
    async-threads:1] [hipe]

    Eshell V10.2  (abort with ^G)
    three@farhad)> net_kernel:connect_node(one@farhad).

    (three@farhad)> nodes().
    []

    (three@farhad)> nodes(hidden).
    [one@farhad]
  #+END_SRC
  in node one@farhad
  #+BEGIN_SRC
  (one@farhad)> nodes().
  [two@farhad]

  (one@farhad)> nodes(hidden).
  [three@farhad]

  (one@farhad)> nodes(connected).
  [two@farhad,three@farhad]
  #+END_SRC
  in node two@farhad
  #+BEGIN_SRC
  (two@farhad)> nodes().
  [one@farhad]

  (two@farhad)> nodes(hidden).
  []
  #+END_SRC

** net_kernel
- transform a non-distributed node into a distributed one:
  #+BEGIN_SRC erlang
  Erlang/OTP 21 [erts-10.2] [source] [64-bit] [smp:4:4] [ds:4:4:10] [async-threads:1] [hipe]

  Eshell V10.2  (abort with ^G)

  1> net_kernel:start([four, shortnames]).
  {ok,<0.80.0>}

  (four@farhad)2>
  #+END_SRC
  use either ~shortnames~ or ~longnames~ to define whether you want to
  have the equivalent of ~-sname~ or ~-name~
- ~net_kernel:start([Name, Type, HeartbeatInMilliseconds])~
  + By default, the heartbeat delay is set to 15 seconds, or 15,000
    milliseconds. After 4 failed heartbeats, a remote node is
    considered dead. The heartbeat delay multiplied by 4 is called the
    tick time.
- ~net_kernel:stop()~ to stop being distributed and go back to being a
  normal node:

** global
- The ~global~ module is a new alternative process registry. It
  automatically spreads its data to all connected nodes, replicates
  data there, handles node failures and supports different conflict
  resolution strategies when nodes get back online again.
- the names you use to register the processes can be any term at all.
- ~global:register_name(Name, Pid)~
- ~global:unregister_name(Name)~
- transfer a name without ever having it point to nothing ~global:re_register_name(Name, Pid)~.
- ~global:whereis_name(Name)~
- ~global:send(Name, Message)~
- A naming conflict will happen when two nodes get connected and both
  of them have two different processes sharing the same name. In
  these cases, global will kill one of them randomly by default. to override it
  #+BEGIN_SRC erlang
    5> Resolve = fun(_Name,Pid1,Pid2) ->            %% pick the process with the most messages in its mailbox
    5>     case process_info(Pid1, message_queue_len) > process_info(Pid2, message_queue_len) of
    5>         true -> Pid1;
    5>         false -> Pid2
    5>     end
    5> end.
    #Fun<erl_eval.18.59269574>

    6> global:register_name({zombie, 12}, self(), Resolve).
    yes
  #+END_SRC
  Some helpers provided by Erlang
  1. ~fun global:random_exit_name/3~ will kill a process
     randomly. This is the default option.
  2. ~fun global:random_notify_name/3~ will randomly pick one of the
     two processes as the one to survive, and it will send
     ~{global_name_conflict, Name}~ to the process that lost.
  3. ~fun global:notify_all_name/3~ it unregisters both pids, and
     sends the message ~{global_name_conflict, Name, OtherPid}~ to both
     processes and lets them resolve the issue themselves so they
     re-register again.
** rpc
- It contains functions that let you execute commands on remote nodes,
  and a few which facilitate parallel operations.
- ~rpc:call/4-5~: It allows you to run a given operation on a remote
  node and get the results locally
  #+BEGIN_SRC erlang
  (one@farhad)> rpc:call(two@farhad, lists, sort, [[a,e,f,t,h,s,a]]).
  [a,a,e,f,h,s,t]
  #+END_SRC
- Promises:
  #+BEGIN_SRC erlang
  (one@farhad)> Key = rpc:async_call(two@farhad, erlang, node, []).
  <0.102.0>

  (one@farhad)> rpc:yield(Key).
  two@farhad
  #+END_SRC
  + If you don't care about the result, then you can use
    ~rpc:cast(Node, Mod, Fun, Args)~ to send a command to another node
    and forget about it.
  + ~rpc:multicall(Nodes, Mod, Fun, Args)~
  + ~rpc:eval_everywhere(Nodes, Mod, Fun, Args)~
* Distributed OTP
- In standard OTP applications, the application can be loaded,
  started, stopped or unloaded. In distributed applications, we change
  how things work; now the application controller shares its work with
  the distributed application controller, another process sitting next
  to it (usually called dist_ac)

- There are two important concepts handled by distributed
  applications
  1. /failover/: This is a particularly valid strategy when you have
     redundant hardware. You run something on a 'main' computer or
     server, and if it fails, you move it to a backup one. In larger
     scale deployments, you might instead have 50 servers running your
     software (all at maybe 60-70% load) and expect the running ones
     to absorb the load of the failing ones. The concept of failing
     over is mostly important in the former case, and somewhat least
     interesting in the latter one.
  2. /takeover/: The second important concept of distributed OTP
     applications is the takeover. Taking over is the act of a dead
     node coming back from the dead, being known to be more important
     than the backup nodes (maybe it has better hardware), and
     deciding to run the application again. This is usually done by
     gracefully terminating the backup application and starting the
     main one instead.
- config file structure
  #+BEGIN_SRC erlang
    [{kernel,
      [{distributed, [{AppName,
                       TimeOutBeforeRestart,
                       NodeList}]},
       {sync_nodes_mandatory, NecessaryNodes},
       {sync_nodes_optional, OptionalNodes},
       {sync_nodes_timeout, MaxTime}
      ]}].
  #+END_SRC
  + The ~sync_nodes_mandatory~ tuple will work in conjunction with
    ~sync_nodes_timeout~. When you start a distributed virtual machine
    with values set for this, it will stay locked up until all the
    mandatory nodes are also up and locked. Then they get synchronized
    and things start going. If it takes more than ~MaxTime~ to get all
    the nodes up, then they will all crash before starting.
- distributed OTP applications work best when working with releases
  that ensure that all the relevant parts of the system are in place.
* Common Test
- [[http://erlang.org/doc/apps/common_test/users_guide.html][Common Test]] user's guide (fucking complicated)
- the smaller what you test is, the more appropriate EUnit will
  be. The larger your test is, the more appropriate Common Test will
  be.
- Since Common Test is appropriate for system testing, it will assume
  two things:
  1. We will need data to instantiate our stuff
  2. We will need a place to store all that side-effecty stuff we do,
     because we're messy people.

- Common Test will regularly be organized as follows
  #+BEGIN_SRC
        +-----------------------------------------------+
        |                 test root                     |
        |   +---------------------------------------+   |
        |   |             test object directory     |   |
        |   |   +-------------------------------+   |   |
        |   |   |         test suite            |   |   |
        |   |   |   +------------------------+  |   |   |
        |   |   |   |     test case          |  |   |   |
        |   |   |   +------------------------+  |   |   |
        |   |   +-------------------------------+   |   |
        |   +---------------------------------------+   |
        +-----------------------------------------------+
  #+END_SRC
  + The *test case* is the simplest one. It's a bit of code that either
    fails or succeeds. If the case crashes, the test is unsuccessful
    Otherwise, the test case is thought to be successful. In Common
    Test, test cases are single functions. All these functions live in
    a *test suite*, a module that takes care of regrouping related
    test cases together. Each test suite will then live in a
    directory, the *Test Object Directory*. The *test root* is a
    directory that contains many test object directories, but due to
    the nature of OTP applications often being developed individually,
    many Erlang programmers tend to omit that layer.

- Each test suite is a module that ends with ~_SUITE~.
  + Each suite is allowed to have one /data directory/, usually named
    ~Module_SUITE_data/~
- Whenever you run the tests, Common Test will find some place to log
  stuff
- sample test suite
  #+BEGIN_SRC erlang
    -module(basic_SUITE).
    -include_lib("common_test/include/ct.hrl").
    -export([all/0]).
    -export([test1/1, test2/1]).


    all() -> [test1,test2].

    test1(_Config) ->
        1 = 1.

    test2(_Config) ->
        A = 0,
        1/A.
  #+END_SRC
  + ~_Config~ variables contain the initial state your test cases will
    require. That state is literally a proplist, and it initially
    contains two values, ~data_dir~ and ~priv_dir~, the two directories we
    have for our static data and the one where we can mess around.
  + to run from command line: ~ct_run -suite Name_SUITE~
  + from Erlang shell
    #+BEGIN_SRC erlang
    $ erl
    ...
    1> ct:run_test([{suite, basic_SUITE}]).
    #+END_SRC
- Testing With State
  #+BEGIN_SRC erlang
    -module(state_SUITE).
    -include_lib("common_test/include/ct.hrl").

    -export([all/0, init_per_testcase/2, end_per_testcase/2]).
    -export([ets_tests/1]).

    all() -> [ets_tests].

    init_per_testcase(ets_tests, Config) ->
        TabId = ets:new(account, [ordered_set, public]),
        ets:insert(TabId, {andy, 2131}),
        ets:insert(TabId, {david, 12}),
        ets:insert(TabId, {steve, 12943752}),
        [{table,TabId} | Config].

    end_per_testcase(ets_tests, Config) ->
        ets:delete(?config(table, Config)).

    ets_tests(Config) ->
        TabId = ?config(table, Config),
        [{david, 12}] = ets:lookup(TabId, david),
        steve = ets:last(TabId),
        true = ets:insert(TabId, {zachary, 99}),
        zachary = ets:last(TabId).
  #+END_SRC
  + The ~init_per_testcase~ and ~end_per_testcase~ functions run in
    the same process as the test case itself
** Test Groups
- Common Test test groups allow us to regroup some tests
  hierarchically. Even more, they can regroup some groups within other
  groups
  #+BEGIN_SRC erlang
    groups() -> [{GroupName, GroupProperties, GroupMembers}].
    %% e.g.
    groups() ->
        [{test_case_street_gang,
          [shuffle, sequence],
          [simple_case, more_complex_case,
           emotionally_complex_case,
           {group, name_of_another_test_group}]}].
  #+END_SRC
  + group properties can be
    * empty list / no option
    * ~shuffle~
    * ~parallel~
    * ~sequence~
    * ~{repeat, Times}~
    * ~{repeat_until_any_fail, N}~
    * ~{repeat_until_all_fail, N}~
    * ~{repeat_until_any_succeed, N}~
    * ~{repeat_until_all_succeed, N}~
- example
  + meeting.erl
    #+BEGIN_SRC erlang
      -module(meeting).
      -export([rent_projector/1, use_chairs/1, book_room/1, get_all_bookings/0, start/0, stop/0]).
      -record(bookings, {projector, room, chairs}).

      start() ->
          Pid = spawn(fun() -> loop(#bookings{}) end),
          register(?MODULE, Pid).

      stop() ->
          ?MODULE ! stop.

      rent_projector(Group) ->
          ?MODULE ! {projector, Group}.

      book_room(Group) ->
          ?MODULE ! {room, Group}.

      use_chairs(Group) ->
          ?MODULE ! {chairs, Group}.

      get_all_bookings() ->
          Ref = make_ref(),
          ?MODULE ! {self(), Ref, get_bookings},
          receive
              {Ref, Reply} ->
                  Reply
          end.

      loop(B = #bookings{}) ->
          receive
              stop -> ok;
              {From, Ref, get_bookings} ->
                  From ! {Ref, [{room, B#bookings.room},
                                {chairs, B#bookings.chairs},
                                {projector, B#bookings.projector}]},
                  loop(B);
              {room, Group} ->
                  loop(B#bookings{room=Group});
              {chairs, Group} ->
                  loop(B#bookings{chairs=Group});
              {projector, Group} ->
                  loop(B#bookings{projector=Group})
          end.
    #+END_SRC
  + meeting_SUITE.erl
    #+BEGIN_SRC erlang
      -module(meeting_SUITE).
      -include_lib("common_test/include/ct.hrl").
      -export([all/0, groups/0, init_per_group/2, end_per_group/2]).
      -export([carla/1, mark/1, dog/1, all_same_owner/1]).

      %% Regroup the tests as groups that will let you try to see if the 'meeting.erl'
      %% modules contains concurrency errors or not.

      all() -> [{group, session}].

      groups() -> [{session,
                    [],
                    [{group, clients}, all_same_owner]},
                   {clients,
                    [parallel, {repeat, 10}],
                    [carla, mark, dog]}].

      init_per_group(session, Config) ->
          meeting:start(),
          Config;
      init_per_group(_, Config) ->
          Config.

      end_per_group(session, _Config) ->
          meeting:stop();
      end_per_group(_, _Config) ->
          ok.

      carla(_Config) ->
          meeting:book_room(women),
          timer:sleep(10),
          meeting:rent_projector(women),
          timer:sleep(10),
          meeting:use_chairs(women).

      mark(_Config) ->
          meeting:rent_projector(men),
          timer:sleep(10),
          meeting:use_chairs(men),
          timer:sleep(10),
          meeting:book_room(men).

      dog(_Config) ->
          meeting:rent_projector(animals),
          timer:sleep(10),
          meeting:use_chairs(animals),
          timer:sleep(10),
          meeting:book_room(animals).

      all_same_owner(_Config) ->
          [{_,Owner}, {_, Owner}, {_, Owner}] = meeting:get_all_bookings().
    #+END_SRC
  + result
    #+BEGIN_SRC shell
      erl> ct_run:run_test([{suite, meeting_SUITE}]).
      ct_run:run_test([{suite, meeting_SUITE}]).

      Common Test starting (cwd is /home/farhad/play/erlang/commonTest)


      Common Test: Running make in test directories...

      CWD set to: "/home/farhad/play/erlang/commonTest/ct_run.nonode@nohost.2019-01-26_20.43.22"

      TEST INFO: 1 test(s), 1 suite(s)

      Testing erlang.commonTest.meeting_SUITE: Starting test (with repeated test cases)

      - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
      meeting_SUITE:all_same_owner failed on line 51
      Reason: {badmatch,[{room,animals},{chairs,women},{projector,women}]}
      - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

      Testing erlang.commonTest.meeting_SUITE: *** FAILED test case 31 ***
      Testing erlang.commonTest.meeting_SUITE: TEST COMPLETE, 30 ok, 1 failed of 31 test cases

      Updating /home/farhad/play/erlang/commonTest/index.html ... done
      Updating /home/farhad/play/erlang/commonTest/all_runs.html ... done
      {30,1,{0,0}}
    #+END_SRC
- while the init functions of test cases ran in the same process as
  the test case, the init functions of groups run in distinct
  processes from the tests. This means that whenever you initialize
  actors that get linked to the process that spawned them, you have to
  make sure to first unlink them. In the case of ETS tables, you have
  to define a heir to make sure it doesn't disappear. And so on for
  all other concepts that get attached to a process (sockets, file
  descriptors, etc.).
** Test Suites
- The ~init_per_suite/1~ and ~end_per_suite/1~ functions will run only
  once, respectively before and after all of the groups or test
  cases. They'll be mostly useful when dealing with general state and
  dependencies that will be required for all tests. This can include
  manually starting applications you depend on, for example.
** Test Specifications
- Test specifications are special files that let you detail everything
  about how you want to have the tests run, and they work with the
  Erlang shell and the command line.
- Here's a few of the items it can have
  + ~{include, IncludeDirectories}~
    * When Common Test automatically compiles suites, this option
      lets you specify where it should look for include files in order
      to make sure they're there. The ~IncludeDirectories~ value has to
      be a string (list) or a list of strings (list of lists).
  + ~{logdir, LoggingDirectory}~
    * When logging, all logs should be moved to the ~LoggingDirectory~,
      a string. Note that the directory must exist before the tests
      are run, otherwise Common Test will complain.
  + ~{suites, Directory, Suites}~
    * Finds the given suites in ~Directory~. Suites can be an atom
      (~some_SUITE~), a list of atoms, or the atom all to run all the
      suites in a directory.
  + ~{skip_suites, Directory, Suites, Comment}~
    * This subtracts a list of suites from those previously declared
      and skips them. The ~Comment~ argument is a string explaining why
      you decided to skip them. This comment will be put in the final
      HTML logs. The tables will show a yellow 'SKIPPED: Reason' where
      Reason is whatever ~Comment~ contained.
  + ~{groups, Directory, Suite, Groups}~
    * This is an option to pick only a few groups from a given
      suite. The ~Groups~ variable can be a single atom (the group name)
      or all for all groups. The value can also be more complex,
      letting you override the group definitions inside ~groups()~
      within the test case by picking a value like ~{GroupName, [parallel]}~,
      which will override ~GroupName's~ options for ~parallel~, without needing
      to recompile tests.
  + ~{groups, Directory, Suite, Groups, {cases,Cases}}~
    * Similar to the one above, but it lets you specify some test
      cases to include in the tests by substituting ~Cases~ by a single
      case name (an atom), a list of names, or the atom ~all~.
  + ~{skip_groups, Directory, Suite, Groups, Comment}~
    * It allows one to skip test groups, much like the skip_suites for
      suites.
  + ~{skip_groups, Directory, Suite, Groups, {cases,Cases}, Comment}~
    * Similar to the one above, but with specific test cases to skip
      on top of it.
  + ~{cases, Directory, Suite, Cases}~
    * Runs specific test cases from a given suite. Cases can be an
      atom, a list of atoms, or all.
  + ~{skip_cases, Directory, Suite, Cases, Comment}~
    * This is similar to ~skip_suites~, except we choose specific test
      cases to avoid with this one.
  + ~{alias, Alias, Directory}~
    * Because it gets very annoying to write all these directory names
      (especially if they're full names), Common Test lets you
      substitute them with aliases (atoms). This is pretty useful in
      order to be concise.
  + sample
    spec.spec
    #+BEGIN_SRC erlang
      {alias, demo, "./demo/"}.
      {alias, meeting, "./meeting/"}.
      {logdir, "./logs/"}.

      {suites, meeting, all}.
      {suites, demo, all}.
      {skip_cases, demo, basic_SUITE, test2, "This test fails on purpose"}.
    #+END_SRC
    to run the tests ~ct_run -spec spec.spec~
** Large-Scale Testing: Common Test goes distributed
- Common Test lets you start tests on many different nodes, but also
  has ways to dynamically start these nodes and have them watch each
  other.
- Common Test requires the presence of a central node (the CT master)
  in charge of all the other ones. Everything's going to be directed
  from there, from starting nodes, ordering tests to be run, gathering
  logs, etc.
- spec needs to have
  + ~{node, NodeAlias, NodeName}~
    * Much like ~{alias, AliasAtom, Directory}~ for test suites, groups,
      and cases, except it's used for node names. Both NodeAlias and
      NodeName need to be atoms. This tuple is especially useful
      because ~NodeName~ needs to be a *long node* name, and in some cases
      this can be quite long.
  + ~{init, NodeAlias, Options}~
    * This is the option that lets you start nodes. ~NodeAlias~ can be
      a single node alias, or a list of many of them. The ~Options~
      are those available to the [[http://erlang.org/doc/man/ct_slave.html][ct_slave]] module
      - Here are a few of the options available:
        + ~{username, UserName}~ and ~{password, Password}~
          * Using the host part of the node given by ~NodeAlias~,
            Common Test will try to connect to the given host over
            SSH (on port 22) using the user name and password and run
            from there.
        + ~{startup_functions, [{M,F,A}]}~
          * This option defines a list of functions to be called as
            soon as the other node has booted.
        + ~{erl_flags, String}~
          * This sets standard flags that we'd want to pass to the erl
            application when we start it. For example, if we wanted to
            start a node with ~erl -env ERL_LIBS ../ -config conf_file~,
            the option would be ~{erl_flags, "-env ERL_LIBS ../ -config config_file"}~.
        + ~{monitor_master, true | false}~
          * If the CT master stops running and the option is set to
            ~true~, then the slave node will also be taken down. I do
            recommend using this option if you're spawning the remote
            nodes; otherwise they'll keep running in the background if
            the master dies. Moreover, if you run tests again, Common
            Test will be able to connect to these nodes, and there
            will be some state attached to them.
        + ~{boot_timeout, Seconds}~, ~{init_timeout, Seconds}~, ~{startup_timeout, Seconds}~
          * These three options let you wait for different parts of
            the starting of a remote node. The boot timeout is about
            how long it takes before the node becomes pingable, with a
            default value of 3 seconds. The init timeout is an
            internal timer where the new remote node calls back the CT
            master to tell it it's up. By default, it lasts one
            second. Finally, the startup timeout tells Common Test how
            long to wait for the functions we defined earlier as part
            of the ~startup_functions~ tuple.
        + ~{kill_if_fail, true | false}~
          * This option will react to one of the three timeouts
            above. If any of them are triggered, Common Test will
            abort the connection, skip tests, etc. but not necessarily
            kill the node, unless the option is set to
            ~true~. That's the default value.
- sample
  dist.spec
  #+BEGIN_SRC erlang
    {node, a, 'a@farhad.local'}.
    {node, b, 'b@farhad.local'}.

    {init, [a,b], [{node_start, [{monitor_master, true}]}]}.

    {alias, demo, "./demo/"}.
    {alias, meeting, "./meeting/"}.

    {logdir, all_nodes, "./logs/"}.
    {logdir, master, "./logs/"}.

    {suites, [b], meeting, all}.
    {suites, [a], demo, all}.
    {skip_cases, [a], demo, basic_SUITE, test2, "This test fails on purpose"}.
  #+END_SRC
  how to run? having ~a@farhad.local~ and ~a@farhad.local~ up and
  running we can run the tests like:
  #+BEGIN_SRC shell
    erlang/commonTest/ct ▶ erl -name ct@farhad.local
    ...
    (ct@farhad.local)1> ct_master:run("dist.spec").
  #+END_SRC
* Mnesia
- Mnesia is a layer built on top of ETS and DETS to add a lot of
  functionality to these two databases like:
  1. the ability to write to both ETS and DETS automatically
  2. to both have DETS' persistence and ETS' performance
  3. having the possibility to replicate the database to many
     different Erlang nodes automatically.
  4. transactions (basically means that you're going to be able to do
     multiple operations on one or more tables as if the process doing
     them were the only one to have access to the tables)
- If we refer to the CAP theorem, Mnesia sits on the CP side, rather
  than the AP side,
- Mnesia tables have no built-in type constraints
- Mnesia is centered around the idea of using a record to define a
  table's structure.
  #+BEGIN_SRC erlang
  -record(recipe, {name, ingredients=[], instructions=[], time}).
  #+END_SRC
  + then we can then tell Mnesia to create a recipe table, which would
    store any number of ~#recipe{}~ records as table rows.
  + The primary key, the field by which it is the fastest to look
    things up in a table, would be the recipe ~name~. that's because
    ~name~ is the first item in the record definition for ~#recipe{}~.
- Mnesia tables are global to all the nodes that will be part of its
  cluster. This implies a high potential for name clashes if you're
  not careful.
- Mnesia is built using ETS and DETS tables. This gives us two means
  of storage: on disk, or in memory. We have to pick a strategy! Here
  are the options:
  + ~ram_copies~
    * This option makes it so all data is stored exclusively in ETS,
      so memory only. Memory should be limited to a theoretical 4GB
      (and practically around 3GB) for virtual machines compiled on 32
      bits, but this limit is pushed further away on 64 bits virtual
      machines, assuming there is more than 4GB of memory available.
  + ~disc_only_copies~
    * This option means that the data is stored only in DETS. Disc
      only, and as such the storage is limited to DETS' 2GB limit.
  + ~disc_copies~
    * This option means that the data is stored both in ETS and on
      disk, so both memory and the hard disk. ~disc_copies~ tables are
      not limited by DETS limits, as Mnesia uses a complex system of
      transaction logs and checkpoints that allow to create a
      disk-based backup of the table in memory.
- table type
  + ~set~
  + ~bag~
  + ~ordered_set~: not supported for ~disc_only_copies~ tables
** Schemas
- Although Mnesia can work fine on isolated nodes, it does support
  distribution and replication to many nodes. To know how to store
  tables on disk, how to load them, and what other nodes they should
  be synchronized with, Mnesia needs to have something called a
  schema, holding all that information. By default, Mnesia creates a
  schema directly in memory when it's created. It works fine for
  tables that need to live in RAM only, but when your schema needs to
  survive across many VM restarts, on all the nodes part of the Mnesia
  cluster, things get a bit more complex.

- Mnesia depends on the schema, but Mnesia should also create the
  schema. This creates a weird situation where the schema needs to be
  created by Mnesia without running Mnesia first!
  + We have to call the function ~mnesia:create_schema(ListOfNodes)~
    before starting Mnesia, it will create a bunch of files on each
    node, storing all the table information required. You don't need
    to be connected to the other nodes when calling it, but they need
    to be running; the function will set the connections up and get
    everything working for you.

- Starting Mnesia for the first time creates a schema in memory, which
  is good for ~ram_copies~. Other kinds of tables won't work with it.
- If you create a schema manually before starting Mnesia (or after
  stopping it), you will be able to create tables that sit on disk.
- Start Mnesia, and you can then start creating tables. Tables can't
  be created while Mnesia is not running

- By default, the schema will be created in the current working
  directory, wherever the Erlang node is running. To change this,
  the Mnesia application has a ~dir~ variable that can be set to pick
  where the schema will be stored. You can thus start your node as
  ~erl -name SomeName -mnesia dir where/to/store/the/db~ or set it
  dynamically with ~application:set_env(mnesia, dir, "where/to/store/the/db").~

- For the tables to be created on all nodes, Mnesia needs to run on
  all nodes. For the schema to be created, Mnesia needs to run on no
  nodes.

** Creating
-Once the schema has been created and we've started Mnesia
  (for e.g. by ~application:start(mnesia)~) we can create our tables
  + ~mnesia:create_table/2~
    * ~{attributes, List}~
      - This is a list of all the items in a table. By default it
        takes the form ~[key, value]~, meaning you would need a record
        of the form ~-record(TableName, {key,val})~. to work. Pretty
        much everyone cheats a little bit and uses a special construct
        (a compiler-supported macro, in fact) that extracts the
        element names from a record. The construct looks like a
        function call. To do it with our recpie record, we would pass
        it as ~{attributes, record_info(fields, recipe)}~.
        #+BEGIN_SRC erlang
          erl> rd(foo, {bar,zoo}).
          foo

          erl> #foo{}.
          #foo{bar = undefined,zoo = undefined}

          erl> record_info(fields, foo).
          [bar,zoo]
        #+END_SRC
    * ~{disc_copies, NodeList}~, ~{disc_only_copies, NodeList}~, ~{ram_copies, NodeList}~
      - This is where you specify how to store the tables, Note that
        you can have many of these options present at once.
    * ~{index, ListOfIntegers}~
      - Mnesia tables let you have /indexes/ on top of the basic ETS and
        DETS functionality. This is useful in cases where you are
        planning to build searches on record fields other than the
        primary key.
        #+BEGIN_SRC erlang
        {index, [#recipe.time]}.
        #+END_SRC
    * ~{type, Type}~
      - Type is either ~set~, ~ordered_set~ or ~bag~ tables.
    * ~{local_content, true}~: will let the table be private to each
      node (although RPC would make it trivial to circumvent)
  + ~mnesia:wait_for_tables(TableList, TimeOut)~
    * wait for at most ~TimeOut~ seconds or until the tables are
      available.
** Access And Context
- All modifications or even reads to a database table need to be done
  in something called activity access context. Those are different
  types of transactions or 'ways' to run queries:
  + ~transaction~
    * will run on all nodes or none of them; it succeeds entirely or
      fails entirely.
    * This type of activity context is partially asynchronous: it will
      be synchronous for operations on the local node, but it will
      only wait for the confirmation from other nodes that they /will/
      commit the transaction, *not that they have done it*. The way
      Mnesia works, if the transaction worked locally and everyone
      else agreed to do it, it should work everywhere else. If it
      doesn't, possibly due to failures in the network or hardware,
      the transaction will be reverted at a later point in time; the
      protocol tolerates this for some efficiency reasons, but might
      give you confirmation that a transaction succeeded when it will
      be rolled back later
  + ~sync_transaction~
    * This activity context is pretty much the same as ~transaction~,
      but it is synchronous. If the guarantees of transaction aren't
      enough for you because you don't like the idea of a transaction
      telling you it succeeded when it may have failed due to weird
      errors, especially if you want to do things that have side
      effects (like notifying external services, spawning processes,
      and so on) related to the transaction's success, using
      sync_transaction is what you want. Synchronous transactions will
      wait for the final confirmation for all other nodes before
      returning, making sure everything went fine 100% of the way.
  + ~async_dirty~
    * The ~async_dirty~ activity context basically bypasses all the
      transaction protocols and locking activities (note that it will,
      however, wait for active transactions to finish before
      proceeding). It will however keep on doing everything that
      includes logging, replication, etc. An ~async_dirty~ activity
      context will try to perform all actions locally, and then
      return, leaving other nodes' replication take place
      asynchronously.
  + ~sync_dirty~
    * This activity context is to ~async_dirty~ what ~sync_transaction~
      was to ~transaction~. It will wait for the confirmation that
      things went fine on remote nodes, but will still stay out of all
      locking or transaction contexts. Dirty contexts are generally
      faster than transactions, but absolutely riskier by
      design.
  + These operations are to be wrapped in a ~fun~ and executed by
    calling ~mnesia:activity(Context, Fun).~. The ~fun~ can contain
    any Erlang function call, though be aware that it is possible for
    a transaction to be executed many times in case of failures or
    interruption by other transactions. This means that if a
    transaction that reads a value from a table also sends a message
    before writing something back in, it is entirely possible for the
    message to be sent dozens of times. As such, no side effects of
    the kind should be included in the transaction.
** Reads, Writes, and More
- *write*: By calling ~mnesia:write(Record)~, where the name of the record
  is the name of the table, we're able to insert ~Record~ in the
  table. If the table is of type ~set~ or ~ordered_set~ and the primary
  key (the second field of the record, not its name, under a tuple form),
  the element will be replaced. For ~bag~ tables, the whole record will need to be similar.
- *delete*: ~mnesia:delete(TableName, Key)~
- *read*: ~mnesia:read({TableName, Key})~
- *match_object*:
    + similar to ETS' ~match_object~ function. It uses patterns to
    return entire records from the database table. For example, a
    quick way to look for recipes with a ~given~ time could be done
    with ~mnesia:match_object(#recipe{_ = '_', time = ~given~}).~ It
    will then return a list of all matching entries in the table.
- *select*:
  + can be called as ~mnesia:select(TableName, MatchSpec)~
  + This is similar to the ETS ~select~ function. It works using match
    specifications or ~ets:fun2ms~ as a way to do queries.
** Query List Comprehensions
- Query List Comprehensions are basically a compiler trick using parse
  transforms that let you use list comprehensions for any data
  structure that can be searched and iterated through. They're
  implemented for Mnesia, DETS, and ETS, but can also be implemented
  for things like ~gb_trees~.
- Once you add ~-include_lib("stdlib/include/qlc.hrl").~ to your
  module, you can start using list comprehensions with something
  called a query handle (QH for short) as a generator. The query handle is what
  allows any iterable data structure to work with QLC. In the case of
  Mnesia, what you can do is use ~mnesia:table(TableName)~ as a list
  comprehension generator, and from that point on, you can use list
  comprehensions to query any database table by wrapping them in a
  call to ~qlc:q(...)~. This will in turn return a modified query
  handle, with more details than the one returned by the table. This
  newest one can subsequently be modified some more by using functions
  like ~qlc:sort/1-2~, and can be evaluated by using ~qlc:eval/1~ or
  ~qlc:fold/1~.
- example
  #+BEGIN_SRC erlang
    friend_by_expertise(Expertise) ->
        F = fun() ->
                    qlc:eval(qlc:q(
                               [{Name,C,I,E,find_services(Name)} ||
                                   #mafiapp_friends{name=Name,
                                                    contact=C,
                                                    info=I,
                                                    expertise=E} <- mnesia:table(mafiapp_friends),
                                   E =:= Expertise]))
            end,
        mnesia:activity(transaction, F).
  #+END_SRC
- another example

  #+BEGIN_SRC erlang
    debts(Name) ->
        F = fun() ->
                    QH = qlc:q(
                           [if Name =:= To -> {From,1};
                               Name =:= From -> {To,-1}
                            end || #mafiapp_services{from=From, to=To} <-
                                       mnesia:table(mafiapp_services),
                                   Name =:= To orelse Name =:= From]),
                    qlc:fold(fun({Person,N}, Dict) ->
                                     dict:update(Person, fun(X) -> X + N end, N, Dict)
                             end,
                             dict:new(),
                             QH)
            end,
        lists:sort([{V,K} || {K,V} <- dict:to_list(mnesia:activity(transaction, F))]).
  #+END_SRC
  + The ~qlc:fold~ is used as a way to evaluate the query handle (QH).
* Type Specification and Dialyzer
- Dialyzer's Persistent Lookup Table (PLT):
  #+BEGIN_SRC
  dialyzer --build_plt --apps erts kernel stdlib crypto mnesia sasl common_test eunit
  #+END_SRC
  PLT is a compilation of all the details Dialyzer can
  identify about the applications and modules that are part of your
  standard Erlang distribution, and code outside of OTP too.
  + add additional
    #+BEGIN_SRC
    dialyzer --add_to_plt --apps ssl reltool
    #+END_SRC
  + If you want to add your own applications or modules to the PLT,
    you can do so by using ~-r Directories~, which will look for all
    ~.erl~ or ~.beam~ files (as long as they're compiled with ~debug_info~)
    to add them to the PLT.
  + run over a bunch of libraries
    #+BEGIN_SRC
    dialyzer -r processquest-1.1.0/src regis-1.1.0/src sockserv-1.0.1/src --src
    #+END_SRC
    By default, dialyzer will look for ~.beam~ files. We need to add the
    ~--src~ flag to tell Dialyzer to use ~.erl~ files for its analysis

** types
*** Singleton types
- they refer to a value itself
  | 'some atom' | Any atom can be its own singleton type |
  | 42          | A given integer                        |
  | []          | An empty list                          |
  | {}          | An empty tuple                         |
  | <<>>        | an empty binary                        |

*** Union types built-in types
- Union types is a type that has two atoms in it. We can define them ourselves
- Union types and built-in types generally share a similar syntax, and
  they're noted with the form ~TypeName()~.
- built-in types are pre-defined types, not necessarily possible to build by hand
- a table of built-in types (Note that they do not all have the same
  syntax as union types do. Some of them, like binaries and tuples,
  have a special syntax to make them friendlier to use)
  |-------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | built-in                                  | description                                                                                                                                                                                                                              |
  |-------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | ~any()~                                   | Any Erlang term at all                                                                                                                                                                                                                   |
  | ~none()~                                  | This is a special type that means that no term or type is valid. Usually, when Dialyzer boils down the possible return values of a function to none(), it means the function should crash. It is synonymous with "this stuff won't work. |
  | ~pid()~                                   | A process identifier.                                                                                                                                                                                                                    |
  | ~port()~                                  | P.S.1                                                                                                                                                                                                                                    |
  | ~reference()~                             | Unique values returned by ~make_ref()~ or ~erlang:monitor/2~                                                                                                                                                                             |
  | ~atom()~                                  | Atoms in general                                                                                                                                                                                                                         |
  | ~binary()~                                | A blob of binary data                                                                                                                                                                                                                    |
  | ~<<_:Integer>>~                           | A binary of a known size, where /Integer/ is the size                                                                                                                                                                                    |
  | ~<<_:_*Integer>>~                         | A binary that has a given unit size, but of unspecified length                                                                                                                                                                           |
  | ~<<_:Integer, _:_*OtherInteger>>~         | A mix of both previous forms to specify that a binary can have a minimum length                                                                                                                                                          |
  | ~integer()~                               | Any integer                                                                                                                                                                                                                              |
  | ~N..M~                                    | A range of integers. For example, if you wanted to represent a number of months in a year, the range ~1..12~ could be defined. Note that Dialyzer reserves the right to expand this range into a bigger one                              |
  | ~non_neg_integer()~                       | ntegers that are greater or equal to 0                                                                                                                                                                                                   |
  | ~pos_integer()~                           | Integers greater than 0                                                                                                                                                                                                                  |
  | ~neg_integer()~                           | Integers up to -1                                                                                                                                                                                                                        |
  | ~float()~                                 | Any floating point number                                                                                                                                                                                                                |
  | ~fun()~                                   | Any kind of function                                                                                                                                                                                                                     |
  | ~fun((...) -> Type)~                      | An anonymous function of any arity that returns a given type. A given function that returns lists could be noted as ~fun((...) -> list())~                                                                                               |
  | ~fun(() -> Type)~                         | An anonymous function with no arguments, returning a term of a given type.                                                                                                                                                               |
  | ~fun((Type1, Type2, ..., TypeN) -> Type)~ | An anonymous function taking a given number of arguments of a known type. An example could be a function that handles an integer and a floating point value, which could be declared as ~fun((integer(), float()) -> any())~             |
  | ~[]~                                      | An empty list                                                                                                                                                                                                                            |
  | ~[Type()]~                                | P.S.2                                                                                                                                                                                                                                    |
  | ~[Type(), ...]~                           | This special case of ~[Type()]~ mentions that the list can not be empty.                                                                                                                                                                 |
  | ~tuple()~                                 | Any tuple                                                                                                                                                                                                                                |
  | ~{Type1, Type2, ..., TypeN}~              | A tuple of a known size, with known types. For example, a binary tree node could be defined as ~{'node', any(), any(), any(), any()}~, corresponding to ~{'node', LeftTree, RightTree, Key, Value}~.                                     |
  |                                           |                                                                                                                                                                                                                                          |
  P.S.1: A port is the underlying representation of file descriptors
  (which we rarely see unless we go dig deep inside the innards of
  Erlang libraries), sockets, or generally things that allow Erlang to
  communicate with the outside world, such as the ~erlang:open_port/2~
  function. In the Erlang shell, they look like ~#Port<0.638>~

  P.S.2: A list containing a given type. A list of integers could be
  defined as ~[integer()]~. Alternatively, it can be written as
  ~list(Type())~. Lists can sometimes be improper (like ~[1, 2|a]~).
  As such, Dialyzer has types declared for improper lists with
  ~improper_list(TypeList, TypeEnd)~. The improper list ~[1, 2|a]~
  could be typed as ~improper_list(integer(), atom())~, for
  example. Then, to make matters more complex, it is possible to have
  lists where we are not actually sure whether the list will be proper
  or not. In such circumstances, the type ~maybe_improper_list(TypeList, TypeEnd)~ can be used.

- The notation to represent the union of types is the pipe (~|~). this
  lets us say that a given type /TypeName/ is represented as the union
  of ~Type1 | Type2 | ... | TypeN~

- pre-defined unions
  | Union                    | Descriptin                                                                                                                                                                                                                                                                                  |
  |--------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | ~term()~                 | This is equivalent to ~any()~ and was added because other tools used ~term()~ before. Alternatively, the ~_~ variable can be used as an alias of both ~term()~ and ~any()~                                                                                                                  |
  | ~boolean()~              | ~'true'∣'false'~                                                                                                                                                                                                                                                                            |
  | ~byte()~                 | Defined as ~0..255~, it's any valid byte in existence                                                                                                                                                                                                                                       |
  | ~char()~                 | It's defined as ~0..16#10ffff~, but it isn't clear whether this type refers to specific standards for characters or not. It's extremely general in its approach to avoid conflicts                                                                                                          |
  | ~number()~               | ~integer()∣float()~                                                                                                                                                                                                                                                                         |
  | ~maybe_improper_list()~  | This is a quick alias for ~maybe_improper_list(any(), any())~ for improper lists in general                                                                                                                                                                                                 |
  | ~maybe_improper_list(T)~ | Where /T/ is any given type. This is an alias for ~maybe_improper_list(T, any())~                                                                                                                                                                                                           |
  | ~string()~               | A string is defined as ~[char()]~, a list of characters. There is also ~nonempty_string()~, defined as ~[char(), ...]~. Sadly, there is so far no string type for binary strings only, but that's more because they're blobs of data that are to be interpreted in whatever type you choose |
  | ~iolist()~               | They're defined as ~maybe_improper_list(char()∣binary()∣iolist(), binary()∣[])~. you can see that the iolist is itself defined in terms of iolists                                                                                                                                          |
  | ~module()~               | This is a type standing for module names, and is currently an alias of atom()                                                                                                                                                                                                               |
  | ~timeout()~              | ~non_neg_integer()∣'infinity'~                                                                                                                                                                                                                                                              |
  | ~node()~                 | An Erlang's node name, which is an atom                                                                                                                                                                                                                                                     |
  | ~no_return()~            | This is an alias of ~none()~ intended to be used in the return type of functions. It is particularly meant to annotate functions that loop (hopefully) forever, and thus never return                                                                                                       |
  |                          |                                                                                                                                                                                                                                                                                             |
- The syntax for type declaration in a module is:
  #+BEGIN_SRC erlang
  -type TypeName() :: TypeDefinition.
  #+END_SRC
